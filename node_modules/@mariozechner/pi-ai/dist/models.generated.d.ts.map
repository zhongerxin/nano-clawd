{"version":3,"file":"models.generated.d.ts","sourceRoot":"","sources":["../src/models.generated.ts"],"names":[],"mappings":"AAKA,eAAO,MAAM,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;CAo3YT,CAAC","sourcesContent":["// This file is auto-generated by scripts/generate-models.ts\n// Do not edit manually - run 'npm run generate-models' to update\n\nimport type { Model } from \"./types.js\";\n\nexport const MODELS = {\n\t\"amazon-bedrock\": {\n\t\t\"amazon.nova-2-lite-v1:0\": {\n\t\t\tid: \"amazon.nova-2-lite-v1:0\",\n\t\t\tname: \"Nova 2 Lite\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.33,\n\t\t\t\toutput: 2.75,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"amazon.nova-lite-v1:0\": {\n\t\t\tid: \"amazon.nova-lite-v1:0\",\n\t\t\tname: \"Nova Lite\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.06,\n\t\t\t\toutput: 0.24,\n\t\t\t\tcacheRead: 0.015,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 300000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"amazon.nova-micro-v1:0\": {\n\t\t\tid: \"amazon.nova-micro-v1:0\",\n\t\t\tname: \"Nova Micro\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.035,\n\t\t\t\toutput: 0.14,\n\t\t\t\tcacheRead: 0.00875,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"amazon.nova-premier-v1:0\": {\n\t\t\tid: \"amazon.nova-premier-v1:0\",\n\t\t\tname: \"Nova Premier\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 12.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"amazon.nova-pro-v1:0\": {\n\t\t\tid: \"amazon.nova-pro-v1:0\",\n\t\t\tname: \"Nova Pro\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.8,\n\t\t\t\toutput: 3.2,\n\t\t\t\tcacheRead: 0.2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 300000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"amazon.titan-text-express-v1\": {\n\t\t\tid: \"amazon.titan-text-express-v1\",\n\t\t\tname: \"Titan Text G1 - Express\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"amazon.titan-text-express-v1:0:8k\": {\n\t\t\tid: \"amazon.titan-text-express-v1:0:8k\",\n\t\t\tname: \"Titan Text G1 - Express\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-3-5-haiku-20241022-v1:0\": {\n\t\t\tid: \"anthropic.claude-3-5-haiku-20241022-v1:0\",\n\t\t\tname: \"Claude Haiku 3.5\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.8,\n\t\t\t\toutput: 4,\n\t\t\t\tcacheRead: 0.08,\n\t\t\t\tcacheWrite: 1,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-3-5-sonnet-20240620-v1:0\": {\n\t\t\tid: \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n\t\t\tname: \"Claude Sonnet 3.5\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-3-5-sonnet-20241022-v2:0\": {\n\t\t\tid: \"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n\t\t\tname: \"Claude Sonnet 3.5 v2\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-3-7-sonnet-20250219-v1:0\": {\n\t\t\tid: \"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n\t\t\tname: \"Claude Sonnet 3.7\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-3-haiku-20240307-v1:0\": {\n\t\t\tid: \"anthropic.claude-3-haiku-20240307-v1:0\",\n\t\t\tname: \"Claude Haiku 3\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 1.25,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-3-opus-20240229-v1:0\": {\n\t\t\tid: \"anthropic.claude-3-opus-20240229-v1:0\",\n\t\t\tname: \"Claude Opus 3\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-3-sonnet-20240229-v1:0\": {\n\t\t\tid: \"anthropic.claude-3-sonnet-20240229-v1:0\",\n\t\t\tname: \"Claude Sonnet 3\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-haiku-4-5-20251001-v1:0\": {\n\t\t\tid: \"anthropic.claude-haiku-4-5-20251001-v1:0\",\n\t\t\tname: \"Claude Haiku 4.5\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 1.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-opus-4-1-20250805-v1:0\": {\n\t\t\tid: \"anthropic.claude-opus-4-1-20250805-v1:0\",\n\t\t\tname: \"Claude Opus 4.1\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-opus-4-20250514-v1:0\": {\n\t\t\tid: \"anthropic.claude-opus-4-20250514-v1:0\",\n\t\t\tname: \"Claude Opus 4\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-opus-4-5-20251101-v1:0\": {\n\t\t\tid: \"anthropic.claude-opus-4-5-20251101-v1:0\",\n\t\t\tname: \"Claude Opus 4.5\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-opus-4-6-v1\": {\n\t\t\tid: \"anthropic.claude-opus-4-6-v1\",\n\t\t\tname: \"Claude Opus 4.6\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-sonnet-4-20250514-v1:0\": {\n\t\t\tid: \"anthropic.claude-sonnet-4-20250514-v1:0\",\n\t\t\tname: \"Claude Sonnet 4\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"anthropic.claude-sonnet-4-5-20250929-v1:0\": {\n\t\t\tid: \"anthropic.claude-sonnet-4-5-20250929-v1:0\",\n\t\t\tname: \"Claude Sonnet 4.5\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"cohere.command-r-plus-v1:0\": {\n\t\t\tid: \"cohere.command-r-plus-v1:0\",\n\t\t\tname: \"Command R+\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"cohere.command-r-v1:0\": {\n\t\t\tid: \"cohere.command-r-v1:0\",\n\t\t\tname: \"Command R\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"deepseek.r1-v1:0\": {\n\t\t\tid: \"deepseek.r1-v1:0\",\n\t\t\tname: \"DeepSeek-R1\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.35,\n\t\t\t\toutput: 5.4,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"deepseek.v3-v1:0\": {\n\t\t\tid: \"deepseek.v3-v1:0\",\n\t\t\tname: \"DeepSeek-V3.1\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.58,\n\t\t\t\toutput: 1.68,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 81920,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"deepseek.v3.2-v1:0\": {\n\t\t\tid: \"deepseek.v3.2-v1:0\",\n\t\t\tname: \"DeepSeek-V3.2\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.62,\n\t\t\t\toutput: 1.85,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 81920,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"eu.anthropic.claude-haiku-4-5-20251001-v1:0\": {\n\t\t\tid: \"eu.anthropic.claude-haiku-4-5-20251001-v1:0\",\n\t\t\tname: \"Claude Haiku 4.5 (EU)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 1.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"eu.anthropic.claude-opus-4-5-20251101-v1:0\": {\n\t\t\tid: \"eu.anthropic.claude-opus-4-5-20251101-v1:0\",\n\t\t\tname: \"Claude Opus 4.5 (EU)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"eu.anthropic.claude-opus-4-6-v1\": {\n\t\t\tid: \"eu.anthropic.claude-opus-4-6-v1\",\n\t\t\tname: \"Claude Opus 4.6 (EU)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"eu.anthropic.claude-sonnet-4-20250514-v1:0\": {\n\t\t\tid: \"eu.anthropic.claude-sonnet-4-20250514-v1:0\",\n\t\t\tname: \"Claude Sonnet 4 (EU)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"eu.anthropic.claude-sonnet-4-5-20250929-v1:0\": {\n\t\t\tid: \"eu.anthropic.claude-sonnet-4-5-20250929-v1:0\",\n\t\t\tname: \"Claude Sonnet 4.5 (EU)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"global.anthropic.claude-haiku-4-5-20251001-v1:0\": {\n\t\t\tid: \"global.anthropic.claude-haiku-4-5-20251001-v1:0\",\n\t\t\tname: \"Claude Haiku 4.5 (Global)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 1.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"global.anthropic.claude-opus-4-5-20251101-v1:0\": {\n\t\t\tid: \"global.anthropic.claude-opus-4-5-20251101-v1:0\",\n\t\t\tname: \"Claude Opus 4.5 (Global)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"global.anthropic.claude-opus-4-6-v1\": {\n\t\t\tid: \"global.anthropic.claude-opus-4-6-v1\",\n\t\t\tname: \"Claude Opus 4.6 (Global)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"global.anthropic.claude-sonnet-4-20250514-v1:0\": {\n\t\t\tid: \"global.anthropic.claude-sonnet-4-20250514-v1:0\",\n\t\t\tname: \"Claude Sonnet 4 (Global)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"global.anthropic.claude-sonnet-4-5-20250929-v1:0\": {\n\t\t\tid: \"global.anthropic.claude-sonnet-4-5-20250929-v1:0\",\n\t\t\tname: \"Claude Sonnet 4.5 (Global)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"google.gemma-3-27b-it\": {\n\t\t\tid: \"google.gemma-3-27b-it\",\n\t\t\tname: \"Google Gemma 3 27B Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.12,\n\t\t\t\toutput: 0.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 202752,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"google.gemma-3-4b-it\": {\n\t\t\tid: \"google.gemma-3-4b-it\",\n\t\t\tname: \"Gemma 3 4B IT\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.04,\n\t\t\t\toutput: 0.08,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"meta.llama3-1-70b-instruct-v1:0\": {\n\t\t\tid: \"meta.llama3-1-70b-instruct-v1:0\",\n\t\t\tname: \"Llama 3.1 70B Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.72,\n\t\t\t\toutput: 0.72,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"meta.llama3-1-8b-instruct-v1:0\": {\n\t\t\tid: \"meta.llama3-1-8b-instruct-v1:0\",\n\t\t\tname: \"Llama 3.1 8B Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.22,\n\t\t\t\toutput: 0.22,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"meta.llama3-2-11b-instruct-v1:0\": {\n\t\t\tid: \"meta.llama3-2-11b-instruct-v1:0\",\n\t\t\tname: \"Llama 3.2 11B Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.16,\n\t\t\t\toutput: 0.16,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"meta.llama3-2-1b-instruct-v1:0\": {\n\t\t\tid: \"meta.llama3-2-1b-instruct-v1:0\",\n\t\t\tname: \"Llama 3.2 1B Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"meta.llama3-2-3b-instruct-v1:0\": {\n\t\t\tid: \"meta.llama3-2-3b-instruct-v1:0\",\n\t\t\tname: \"Llama 3.2 3B Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"meta.llama3-2-90b-instruct-v1:0\": {\n\t\t\tid: \"meta.llama3-2-90b-instruct-v1:0\",\n\t\t\tname: \"Llama 3.2 90B Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.72,\n\t\t\t\toutput: 0.72,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"meta.llama3-3-70b-instruct-v1:0\": {\n\t\t\tid: \"meta.llama3-3-70b-instruct-v1:0\",\n\t\t\tname: \"Llama 3.3 70B Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.72,\n\t\t\t\toutput: 0.72,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"meta.llama4-maverick-17b-instruct-v1:0\": {\n\t\t\tid: \"meta.llama4-maverick-17b-instruct-v1:0\",\n\t\t\tname: \"Llama 4 Maverick 17B Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.24,\n\t\t\t\toutput: 0.97,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"meta.llama4-scout-17b-instruct-v1:0\": {\n\t\t\tid: \"meta.llama4-scout-17b-instruct-v1:0\",\n\t\t\tname: \"Llama 4 Scout 17B Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.17,\n\t\t\t\toutput: 0.66,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 3500000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"minimax.minimax-m2\": {\n\t\t\tid: \"minimax.minimax-m2\",\n\t\t\tname: \"MiniMax M2\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204608,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"minimax.minimax-m2.1\": {\n\t\t\tid: \"minimax.minimax-m2.1\",\n\t\t\tname: \"MiniMax M2.1\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"mistral.ministral-3-14b-instruct\": {\n\t\t\tid: \"mistral.ministral-3-14b-instruct\",\n\t\t\tname: \"Ministral 14B 3.0\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 0.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"mistral.ministral-3-8b-instruct\": {\n\t\t\tid: \"mistral.ministral-3-8b-instruct\",\n\t\t\tname: \"Ministral 3 8B\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"mistral.mistral-large-2402-v1:0\": {\n\t\t\tid: \"mistral.mistral-large-2402-v1:0\",\n\t\t\tname: \"Mistral Large (24.02)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"mistral.voxtral-mini-3b-2507\": {\n\t\t\tid: \"mistral.voxtral-mini-3b-2507\",\n\t\t\tname: \"Voxtral Mini 3B 2507\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.04,\n\t\t\t\toutput: 0.04,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"mistral.voxtral-small-24b-2507\": {\n\t\t\tid: \"mistral.voxtral-small-24b-2507\",\n\t\t\tname: \"Voxtral Small 24B 2507\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.35,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"moonshot.kimi-k2-thinking\": {\n\t\t\tid: \"moonshot.kimi-k2-thinking\",\n\t\t\tname: \"Kimi K2 Thinking\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"moonshotai.kimi-k2.5\": {\n\t\t\tid: \"moonshotai.kimi-k2.5\",\n\t\t\tname: \"Kimi K2.5\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"nvidia.nemotron-nano-12b-v2\": {\n\t\t\tid: \"nvidia.nemotron-nano-12b-v2\",\n\t\t\tname: \"NVIDIA Nemotron Nano 12B v2 VL BF16\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"nvidia.nemotron-nano-9b-v2\": {\n\t\t\tid: \"nvidia.nemotron-nano-9b-v2\",\n\t\t\tname: \"NVIDIA Nemotron Nano 9B v2\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.06,\n\t\t\t\toutput: 0.23,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"openai.gpt-oss-120b-1:0\": {\n\t\t\tid: \"openai.gpt-oss-120b-1:0\",\n\t\t\tname: \"gpt-oss-120b\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"openai.gpt-oss-20b-1:0\": {\n\t\t\tid: \"openai.gpt-oss-20b-1:0\",\n\t\t\tname: \"gpt-oss-20b\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.07,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"openai.gpt-oss-safeguard-120b\": {\n\t\t\tid: \"openai.gpt-oss-safeguard-120b\",\n\t\t\tname: \"GPT OSS Safeguard 120B\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"openai.gpt-oss-safeguard-20b\": {\n\t\t\tid: \"openai.gpt-oss-safeguard-20b\",\n\t\t\tname: \"GPT OSS Safeguard 20B\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.07,\n\t\t\t\toutput: 0.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"qwen.qwen3-235b-a22b-2507-v1:0\": {\n\t\t\tid: \"qwen.qwen3-235b-a22b-2507-v1:0\",\n\t\t\tname: \"Qwen3 235B A22B 2507\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.22,\n\t\t\t\toutput: 0.88,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"qwen.qwen3-32b-v1:0\": {\n\t\t\tid: \"qwen.qwen3-32b-v1:0\",\n\t\t\tname: \"Qwen3 32B (dense)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 16384,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"qwen.qwen3-coder-30b-a3b-v1:0\": {\n\t\t\tid: \"qwen.qwen3-coder-30b-a3b-v1:0\",\n\t\t\tname: \"Qwen3 Coder 30B A3B Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"qwen.qwen3-coder-480b-a35b-v1:0\": {\n\t\t\tid: \"qwen.qwen3-coder-480b-a35b-v1:0\",\n\t\t\tname: \"Qwen3 Coder 480B A35B Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.22,\n\t\t\t\toutput: 1.8,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"qwen.qwen3-next-80b-a3b\": {\n\t\t\tid: \"qwen.qwen3-next-80b-a3b\",\n\t\t\tname: \"Qwen/Qwen3-Next-80B-A3B-Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.14,\n\t\t\t\toutput: 1.4,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262000,\n\t\t\tmaxTokens: 262000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"qwen.qwen3-vl-235b-a22b\": {\n\t\t\tid: \"qwen.qwen3-vl-235b-a22b\",\n\t\t\tname: \"Qwen/Qwen3-VL-235B-A22B-Instruct\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262000,\n\t\t\tmaxTokens: 262000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"us.anthropic.claude-haiku-4-5-20251001-v1:0\": {\n\t\t\tid: \"us.anthropic.claude-haiku-4-5-20251001-v1:0\",\n\t\t\tname: \"Claude Haiku 4.5 (US)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 1.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"us.anthropic.claude-opus-4-1-20250805-v1:0\": {\n\t\t\tid: \"us.anthropic.claude-opus-4-1-20250805-v1:0\",\n\t\t\tname: \"Claude Opus 4.1 (US)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"us.anthropic.claude-opus-4-20250514-v1:0\": {\n\t\t\tid: \"us.anthropic.claude-opus-4-20250514-v1:0\",\n\t\t\tname: \"Claude Opus 4 (US)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"us.anthropic.claude-opus-4-5-20251101-v1:0\": {\n\t\t\tid: \"us.anthropic.claude-opus-4-5-20251101-v1:0\",\n\t\t\tname: \"Claude Opus 4.5 (US)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"us.anthropic.claude-opus-4-6-v1\": {\n\t\t\tid: \"us.anthropic.claude-opus-4-6-v1\",\n\t\t\tname: \"Claude Opus 4.6 (US)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"us.anthropic.claude-sonnet-4-20250514-v1:0\": {\n\t\t\tid: \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n\t\t\tname: \"Claude Sonnet 4 (US)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"us.anthropic.claude-sonnet-4-5-20250929-v1:0\": {\n\t\t\tid: \"us.anthropic.claude-sonnet-4-5-20250929-v1:0\",\n\t\t\tname: \"Claude Sonnet 4.5 (US)\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"writer.palmyra-x4-v1:0\": {\n\t\t\tid: \"writer.palmyra-x4-v1:0\",\n\t\t\tname: \"Palmyra X4\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 122880,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"writer.palmyra-x5-v1:0\": {\n\t\t\tid: \"writer.palmyra-x5-v1:0\",\n\t\t\tname: \"Palmyra X5\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1040000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"zai.glm-4.7\": {\n\t\t\tid: \"zai.glm-4.7\",\n\t\t\tname: \"GLM-4.7\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t\t\"zai.glm-4.7-flash\": {\n\t\t\tid: \"zai.glm-4.7-flash\",\n\t\t\tname: \"GLM-4.7-Flash\",\n\t\t\tapi: \"bedrock-converse-stream\",\n\t\t\tprovider: \"amazon-bedrock\",\n\t\t\tbaseUrl: \"https://bedrock-runtime.us-east-1.amazonaws.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.07,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"bedrock-converse-stream\">,\n\t},\n\t\"anthropic\": {\n\t\t\"claude-3-5-haiku-20241022\": {\n\t\t\tid: \"claude-3-5-haiku-20241022\",\n\t\t\tname: \"Claude Haiku 3.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.8,\n\t\t\t\toutput: 4,\n\t\t\t\tcacheRead: 0.08,\n\t\t\t\tcacheWrite: 1,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-3-5-haiku-latest\": {\n\t\t\tid: \"claude-3-5-haiku-latest\",\n\t\t\tname: \"Claude Haiku 3.5 (latest)\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.8,\n\t\t\t\toutput: 4,\n\t\t\t\tcacheRead: 0.08,\n\t\t\t\tcacheWrite: 1,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-3-5-sonnet-20240620\": {\n\t\t\tid: \"claude-3-5-sonnet-20240620\",\n\t\t\tname: \"Claude Sonnet 3.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-3-5-sonnet-20241022\": {\n\t\t\tid: \"claude-3-5-sonnet-20241022\",\n\t\t\tname: \"Claude Sonnet 3.5 v2\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-3-7-sonnet-20250219\": {\n\t\t\tid: \"claude-3-7-sonnet-20250219\",\n\t\t\tname: \"Claude Sonnet 3.7\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-3-7-sonnet-latest\": {\n\t\t\tid: \"claude-3-7-sonnet-latest\",\n\t\t\tname: \"Claude Sonnet 3.7 (latest)\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-3-haiku-20240307\": {\n\t\t\tid: \"claude-3-haiku-20240307\",\n\t\t\tname: \"Claude Haiku 3\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 1.25,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0.3,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-3-opus-20240229\": {\n\t\t\tid: \"claude-3-opus-20240229\",\n\t\t\tname: \"Claude Opus 3\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-3-sonnet-20240229\": {\n\t\t\tid: \"claude-3-sonnet-20240229\",\n\t\t\tname: \"Claude Sonnet 3\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 0.3,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-haiku-4-5\": {\n\t\t\tid: \"claude-haiku-4-5\",\n\t\t\tname: \"Claude Haiku 4.5 (latest)\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 1.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-haiku-4-5-20251001\": {\n\t\t\tid: \"claude-haiku-4-5-20251001\",\n\t\t\tname: \"Claude Haiku 4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 1.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-opus-4-0\": {\n\t\t\tid: \"claude-opus-4-0\",\n\t\t\tname: \"Claude Opus 4 (latest)\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-opus-4-1\": {\n\t\t\tid: \"claude-opus-4-1\",\n\t\t\tname: \"Claude Opus 4.1 (latest)\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-opus-4-1-20250805\": {\n\t\t\tid: \"claude-opus-4-1-20250805\",\n\t\t\tname: \"Claude Opus 4.1\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-opus-4-20250514\": {\n\t\t\tid: \"claude-opus-4-20250514\",\n\t\t\tname: \"Claude Opus 4\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-opus-4-5\": {\n\t\t\tid: \"claude-opus-4-5\",\n\t\t\tname: \"Claude Opus 4.5 (latest)\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-opus-4-5-20251101\": {\n\t\t\tid: \"claude-opus-4-5-20251101\",\n\t\t\tname: \"Claude Opus 4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-opus-4-6\": {\n\t\t\tid: \"claude-opus-4-6\",\n\t\t\tname: \"Claude Opus 4.6\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-sonnet-4-0\": {\n\t\t\tid: \"claude-sonnet-4-0\",\n\t\t\tname: \"Claude Sonnet 4 (latest)\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-sonnet-4-20250514\": {\n\t\t\tid: \"claude-sonnet-4-20250514\",\n\t\t\tname: \"Claude Sonnet 4\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-sonnet-4-5\": {\n\t\t\tid: \"claude-sonnet-4-5\",\n\t\t\tname: \"Claude Sonnet 4.5 (latest)\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-sonnet-4-5-20250929\": {\n\t\t\tid: \"claude-sonnet-4-5-20250929\",\n\t\t\tname: \"Claude Sonnet 4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-sonnet-4-6\": {\n\t\t\tid: \"claude-sonnet-4-6\",\n\t\t\tname: \"Claude Sonnet 4.6\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"anthropic\",\n\t\t\tbaseUrl: \"https://api.anthropic.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t},\n\t\"azure-openai-responses\": {\n\t\t\"codex-mini-latest\": {\n\t\t\tid: \"codex-mini-latest\",\n\t\t\tname: \"Codex Mini\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.5,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0.375,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-4\": {\n\t\t\tid: \"gpt-4\",\n\t\t\tname: \"GPT-4\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 30,\n\t\t\t\toutput: 60,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8192,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-4-turbo\": {\n\t\t\tid: \"gpt-4-turbo\",\n\t\t\tname: \"GPT-4 Turbo\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 10,\n\t\t\t\toutput: 30,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-4.1\": {\n\t\t\tid: \"gpt-4.1\",\n\t\t\tname: \"GPT-4.1\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1047576,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-4.1-mini\": {\n\t\t\tid: \"gpt-4.1-mini\",\n\t\t\tname: \"GPT-4.1 mini\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.4,\n\t\t\t\toutput: 1.6,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1047576,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-4.1-nano\": {\n\t\t\tid: \"gpt-4.1-nano\",\n\t\t\tname: \"GPT-4.1 nano\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1047576,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-4o\": {\n\t\t\tid: \"gpt-4o\",\n\t\t\tname: \"GPT-4o\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-4o-2024-05-13\": {\n\t\t\tid: \"gpt-4o-2024-05-13\",\n\t\t\tname: \"GPT-4o (2024-05-13)\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-4o-2024-08-06\": {\n\t\t\tid: \"gpt-4o-2024-08-06\",\n\t\t\tname: \"GPT-4o (2024-08-06)\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-4o-2024-11-20\": {\n\t\t\tid: \"gpt-4o-2024-11-20\",\n\t\t\tname: \"GPT-4o (2024-11-20)\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-4o-mini\": {\n\t\t\tid: \"gpt-4o-mini\",\n\t\t\tname: \"GPT-4o mini\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0.08,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5\": {\n\t\t\tid: \"gpt-5\",\n\t\t\tname: \"GPT-5\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5-chat-latest\": {\n\t\t\tid: \"gpt-5-chat-latest\",\n\t\t\tname: \"GPT-5 Chat Latest\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5-codex\": {\n\t\t\tid: \"gpt-5-codex\",\n\t\t\tname: \"GPT-5-Codex\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5-mini\": {\n\t\t\tid: \"gpt-5-mini\",\n\t\t\tname: \"GPT-5 Mini\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.025,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5-nano\": {\n\t\t\tid: \"gpt-5-nano\",\n\t\t\tname: \"GPT-5 Nano\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.05,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0.005,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5-pro\": {\n\t\t\tid: \"gpt-5-pro\",\n\t\t\tname: \"GPT-5 Pro\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 120,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 272000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5.1\": {\n\t\t\tid: \"gpt-5.1\",\n\t\t\tname: \"GPT-5.1\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.13,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5.1-chat-latest\": {\n\t\t\tid: \"gpt-5.1-chat-latest\",\n\t\t\tname: \"GPT-5.1 Chat\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5.1-codex\": {\n\t\t\tid: \"gpt-5.1-codex\",\n\t\t\tname: \"GPT-5.1 Codex\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5.1-codex-max\": {\n\t\t\tid: \"gpt-5.1-codex-max\",\n\t\t\tname: \"GPT-5.1 Codex Max\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5.1-codex-mini\": {\n\t\t\tid: \"gpt-5.1-codex-mini\",\n\t\t\tname: \"GPT-5.1 Codex mini\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.025,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5.2\": {\n\t\t\tid: \"gpt-5.2\",\n\t\t\tname: \"GPT-5.2\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5.2-chat-latest\": {\n\t\t\tid: \"gpt-5.2-chat-latest\",\n\t\t\tname: \"GPT-5.2 Chat\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5.2-codex\": {\n\t\t\tid: \"gpt-5.2-codex\",\n\t\t\tname: \"GPT-5.2 Codex\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5.2-pro\": {\n\t\t\tid: \"gpt-5.2-pro\",\n\t\t\tname: \"GPT-5.2 Pro\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 21,\n\t\t\t\toutput: 168,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5.3-codex\": {\n\t\t\tid: \"gpt-5.3-codex\",\n\t\t\tname: \"GPT-5.3 Codex\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"gpt-5.3-codex-spark\": {\n\t\t\tid: \"gpt-5.3-codex-spark\",\n\t\t\tname: \"GPT-5.3 Codex Spark\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"o1\": {\n\t\t\tid: \"o1\",\n\t\t\tname: \"o1\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 60,\n\t\t\t\tcacheRead: 7.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"o1-pro\": {\n\t\t\tid: \"o1-pro\",\n\t\t\tname: \"o1-pro\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 150,\n\t\t\t\toutput: 600,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"o3\": {\n\t\t\tid: \"o3\",\n\t\t\tname: \"o3\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"o3-deep-research\": {\n\t\t\tid: \"o3-deep-research\",\n\t\t\tname: \"o3-deep-research\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 10,\n\t\t\t\toutput: 40,\n\t\t\t\tcacheRead: 2.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"o3-mini\": {\n\t\t\tid: \"o3-mini\",\n\t\t\tname: \"o3-mini\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.1,\n\t\t\t\toutput: 4.4,\n\t\t\t\tcacheRead: 0.55,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"o3-pro\": {\n\t\t\tid: \"o3-pro\",\n\t\t\tname: \"o3-pro\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 20,\n\t\t\t\toutput: 80,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"o4-mini\": {\n\t\t\tid: \"o4-mini\",\n\t\t\tname: \"o4-mini\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.1,\n\t\t\t\toutput: 4.4,\n\t\t\t\tcacheRead: 0.28,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t\t\"o4-mini-deep-research\": {\n\t\t\tid: \"o4-mini-deep-research\",\n\t\t\tname: \"o4-mini-deep-research\",\n\t\t\tapi: \"azure-openai-responses\",\n\t\t\tprovider: \"azure-openai-responses\",\n\t\t\tbaseUrl: \"\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"azure-openai-responses\">,\n\t},\n\t\"cerebras\": {\n\t\t\"gpt-oss-120b\": {\n\t\t\tid: \"gpt-oss-120b\",\n\t\t\tname: \"GPT OSS 120B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"cerebras\",\n\t\t\tbaseUrl: \"https://api.cerebras.ai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 0.69,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"llama3.1-8b\": {\n\t\t\tid: \"llama3.1-8b\",\n\t\t\tname: \"Llama 3.1 8B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"cerebras\",\n\t\t\tbaseUrl: \"https://api.cerebras.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32000,\n\t\t\tmaxTokens: 8000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen-3-235b-a22b-instruct-2507\": {\n\t\t\tid: \"qwen-3-235b-a22b-instruct-2507\",\n\t\t\tname: \"Qwen 3 235B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"cerebras\",\n\t\t\tbaseUrl: \"https://api.cerebras.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"zai-glm-4.7\": {\n\t\t\tid: \"zai-glm-4.7\",\n\t\t\tname: \"Z.AI GLM-4.7\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"cerebras\",\n\t\t\tbaseUrl: \"https://api.cerebras.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.25,\n\t\t\t\toutput: 2.75,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 40000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t},\n\t\"github-copilot\": {\n\t\t\"claude-haiku-4.5\": {\n\t\t\tid: \"claude-haiku-4.5\",\n\t\t\tname: \"Claude Haiku 4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-opus-4.5\": {\n\t\t\tid: \"claude-opus-4.5\",\n\t\t\tname: \"Claude Opus 4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-opus-4.6\": {\n\t\t\tid: \"claude-opus-4.6\",\n\t\t\tname: \"Claude Opus 4.6\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-sonnet-4\": {\n\t\t\tid: \"claude-sonnet-4\",\n\t\t\tname: \"Claude Sonnet 4\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-sonnet-4.5\": {\n\t\t\tid: \"claude-sonnet-4.5\",\n\t\t\tname: \"Claude Sonnet 4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"gemini-2.5-pro\": {\n\t\t\tid: \"gemini-2.5-pro\",\n\t\t\tname: \"Gemini 2.5 Pro\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\tcompat: {\"supportsStore\":false,\"supportsDeveloperRole\":false,\"supportsReasoningEffort\":false},\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"gemini-3-flash-preview\": {\n\t\t\tid: \"gemini-3-flash-preview\",\n\t\t\tname: \"Gemini 3 Flash\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\tcompat: {\"supportsStore\":false,\"supportsDeveloperRole\":false,\"supportsReasoningEffort\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"gemini-3-pro-preview\": {\n\t\t\tid: \"gemini-3-pro-preview\",\n\t\t\tname: \"Gemini 3 Pro Preview\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\tcompat: {\"supportsStore\":false,\"supportsDeveloperRole\":false,\"supportsReasoningEffort\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"gpt-4.1\": {\n\t\t\tid: \"gpt-4.1\",\n\t\t\tname: \"GPT-4.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\tcompat: {\"supportsStore\":false,\"supportsDeveloperRole\":false,\"supportsReasoningEffort\":false},\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 64000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"gpt-4o\": {\n\t\t\tid: \"gpt-4o\",\n\t\t\tname: \"GPT-4o\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\tcompat: {\"supportsStore\":false,\"supportsDeveloperRole\":false,\"supportsReasoningEffort\":false},\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 64000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"gpt-5\": {\n\t\t\tid: \"gpt-5\",\n\t\t\tname: \"GPT-5\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5-mini\": {\n\t\t\tid: \"gpt-5-mini\",\n\t\t\tname: \"GPT-5-mini\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1\": {\n\t\t\tid: \"gpt-5.1\",\n\t\t\tname: \"GPT-5.1\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1-codex\": {\n\t\t\tid: \"gpt-5.1-codex\",\n\t\t\tname: \"GPT-5.1-Codex\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1-codex-max\": {\n\t\t\tid: \"gpt-5.1-codex-max\",\n\t\t\tname: \"GPT-5.1-Codex-max\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1-codex-mini\": {\n\t\t\tid: \"gpt-5.1-codex-mini\",\n\t\t\tname: \"GPT-5.1-Codex-mini\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.2\": {\n\t\t\tid: \"gpt-5.2\",\n\t\t\tname: \"GPT-5.2\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.2-codex\": {\n\t\t\tid: \"gpt-5.2-codex\",\n\t\t\tname: \"GPT-5.2-Codex\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 272000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"grok-code-fast-1\": {\n\t\t\tid: \"grok-code-fast-1\",\n\t\t\tname: \"Grok Code Fast 1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"github-copilot\",\n\t\t\tbaseUrl: \"https://api.individual.githubcopilot.com\",\n\t\t\theaders: {\"User-Agent\":\"GitHubCopilotChat/0.35.0\",\"Editor-Version\":\"vscode/1.107.0\",\"Editor-Plugin-Version\":\"copilot-chat/0.35.0\",\"Copilot-Integration-Id\":\"vscode-chat\"},\n\t\t\tcompat: {\"supportsStore\":false,\"supportsDeveloperRole\":false,\"supportsReasoningEffort\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t},\n\t\"google\": {\n\t\t\"gemini-1.5-flash\": {\n\t\t\tid: \"gemini-1.5-flash\",\n\t\t\tname: \"Gemini 1.5 Flash\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.075,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0.01875,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-1.5-flash-8b\": {\n\t\t\tid: \"gemini-1.5-flash-8b\",\n\t\t\tname: \"Gemini 1.5 Flash-8B\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.0375,\n\t\t\t\toutput: 0.15,\n\t\t\t\tcacheRead: 0.01,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-1.5-pro\": {\n\t\t\tid: \"gemini-1.5-pro\",\n\t\t\tname: \"Gemini 1.5 Pro\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.3125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-2.0-flash\": {\n\t\t\tid: \"gemini-2.0-flash\",\n\t\t\tname: \"Gemini 2.0 Flash\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0.025,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-2.0-flash-lite\": {\n\t\t\tid: \"gemini-2.0-flash-lite\",\n\t\t\tname: \"Gemini 2.0 Flash Lite\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.075,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-2.5-flash\": {\n\t\t\tid: \"gemini-2.5-flash\",\n\t\t\tname: \"Gemini 2.5 Flash\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0.075,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-2.5-flash-lite\": {\n\t\t\tid: \"gemini-2.5-flash-lite\",\n\t\t\tname: \"Gemini 2.5 Flash Lite\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0.025,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-2.5-flash-lite-preview-06-17\": {\n\t\t\tid: \"gemini-2.5-flash-lite-preview-06-17\",\n\t\t\tname: \"Gemini 2.5 Flash Lite Preview 06-17\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0.025,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-2.5-flash-lite-preview-09-2025\": {\n\t\t\tid: \"gemini-2.5-flash-lite-preview-09-2025\",\n\t\t\tname: \"Gemini 2.5 Flash Lite Preview 09-25\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0.025,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-2.5-flash-preview-04-17\": {\n\t\t\tid: \"gemini-2.5-flash-preview-04-17\",\n\t\t\tname: \"Gemini 2.5 Flash Preview 04-17\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0.0375,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-2.5-flash-preview-05-20\": {\n\t\t\tid: \"gemini-2.5-flash-preview-05-20\",\n\t\t\tname: \"Gemini 2.5 Flash Preview 05-20\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0.0375,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-2.5-flash-preview-09-2025\": {\n\t\t\tid: \"gemini-2.5-flash-preview-09-2025\",\n\t\t\tname: \"Gemini 2.5 Flash Preview 09-25\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0.075,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-2.5-pro\": {\n\t\t\tid: \"gemini-2.5-pro\",\n\t\t\tname: \"Gemini 2.5 Pro\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.31,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-2.5-pro-preview-05-06\": {\n\t\t\tid: \"gemini-2.5-pro-preview-05-06\",\n\t\t\tname: \"Gemini 2.5 Pro Preview 05-06\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.31,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-2.5-pro-preview-06-05\": {\n\t\t\tid: \"gemini-2.5-pro-preview-06-05\",\n\t\t\tname: \"Gemini 2.5 Pro Preview 06-05\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.31,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-3-flash-preview\": {\n\t\t\tid: \"gemini-3-flash-preview\",\n\t\t\tname: \"Gemini 3 Flash Preview\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0.05,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-3-pro-preview\": {\n\t\t\tid: \"gemini-3-pro-preview\",\n\t\t\tname: \"Gemini 3 Pro Preview\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 12,\n\t\t\t\tcacheRead: 0.2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-flash-latest\": {\n\t\t\tid: \"gemini-flash-latest\",\n\t\t\tname: \"Gemini Flash Latest\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0.075,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-flash-lite-latest\": {\n\t\t\tid: \"gemini-flash-lite-latest\",\n\t\t\tname: \"Gemini Flash-Lite Latest\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0.025,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-live-2.5-flash\": {\n\t\t\tid: \"gemini-live-2.5-flash\",\n\t\t\tname: \"Gemini Live 2.5 Flash\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 8000,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-live-2.5-flash-preview-native-audio\": {\n\t\t\tid: \"gemini-live-2.5-flash-preview-native-audio\",\n\t\t\tname: \"Gemini Live 2.5 Flash Preview Native Audio\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"google\",\n\t\t\tbaseUrl: \"https://generativelanguage.googleapis.com/v1beta\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t},\n\t\"google-antigravity\": {\n\t\t\"claude-opus-4-5-thinking\": {\n\t\t\tid: \"claude-opus-4-5-thinking\",\n\t\t\tname: \"Claude Opus 4.5 Thinking (Antigravity)\",\n\t\t\tapi: \"google-gemini-cli\",\n\t\t\tprovider: \"google-antigravity\",\n\t\t\tbaseUrl: \"https://daily-cloudcode-pa.sandbox.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"google-gemini-cli\">,\n\t\t\"claude-sonnet-4-5\": {\n\t\t\tid: \"claude-sonnet-4-5\",\n\t\t\tname: \"Claude Sonnet 4.5 (Antigravity)\",\n\t\t\tapi: \"google-gemini-cli\",\n\t\t\tprovider: \"google-antigravity\",\n\t\t\tbaseUrl: \"https://daily-cloudcode-pa.sandbox.googleapis.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"google-gemini-cli\">,\n\t\t\"claude-sonnet-4-5-thinking\": {\n\t\t\tid: \"claude-sonnet-4-5-thinking\",\n\t\t\tname: \"Claude Sonnet 4.5 Thinking (Antigravity)\",\n\t\t\tapi: \"google-gemini-cli\",\n\t\t\tprovider: \"google-antigravity\",\n\t\t\tbaseUrl: \"https://daily-cloudcode-pa.sandbox.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"google-gemini-cli\">,\n\t\t\"gemini-3-flash\": {\n\t\t\tid: \"gemini-3-flash\",\n\t\t\tname: \"Gemini 3 Flash (Antigravity)\",\n\t\t\tapi: \"google-gemini-cli\",\n\t\t\tprovider: \"google-antigravity\",\n\t\t\tbaseUrl: \"https://daily-cloudcode-pa.sandbox.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"google-gemini-cli\">,\n\t\t\"gemini-3-pro-high\": {\n\t\t\tid: \"gemini-3-pro-high\",\n\t\t\tname: \"Gemini 3 Pro High (Antigravity)\",\n\t\t\tapi: \"google-gemini-cli\",\n\t\t\tprovider: \"google-antigravity\",\n\t\t\tbaseUrl: \"https://daily-cloudcode-pa.sandbox.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 12,\n\t\t\t\tcacheRead: 0.2,\n\t\t\t\tcacheWrite: 2.375,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"google-gemini-cli\">,\n\t\t\"gemini-3-pro-low\": {\n\t\t\tid: \"gemini-3-pro-low\",\n\t\t\tname: \"Gemini 3 Pro Low (Antigravity)\",\n\t\t\tapi: \"google-gemini-cli\",\n\t\t\tprovider: \"google-antigravity\",\n\t\t\tbaseUrl: \"https://daily-cloudcode-pa.sandbox.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 12,\n\t\t\t\tcacheRead: 0.2,\n\t\t\t\tcacheWrite: 2.375,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"google-gemini-cli\">,\n\t\t\"gpt-oss-120b-medium\": {\n\t\t\tid: \"gpt-oss-120b-medium\",\n\t\t\tname: \"GPT-OSS 120B Medium (Antigravity)\",\n\t\t\tapi: \"google-gemini-cli\",\n\t\t\tprovider: \"google-antigravity\",\n\t\t\tbaseUrl: \"https://daily-cloudcode-pa.sandbox.googleapis.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09,\n\t\t\t\toutput: 0.36,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"google-gemini-cli\">,\n\t},\n\t\"google-gemini-cli\": {\n\t\t\"gemini-2.0-flash\": {\n\t\t\tid: \"gemini-2.0-flash\",\n\t\t\tname: \"Gemini 2.0 Flash (Cloud Code Assist)\",\n\t\t\tapi: \"google-gemini-cli\",\n\t\t\tprovider: \"google-gemini-cli\",\n\t\t\tbaseUrl: \"https://cloudcode-pa.googleapis.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"google-gemini-cli\">,\n\t\t\"gemini-2.5-flash\": {\n\t\t\tid: \"gemini-2.5-flash\",\n\t\t\tname: \"Gemini 2.5 Flash (Cloud Code Assist)\",\n\t\t\tapi: \"google-gemini-cli\",\n\t\t\tprovider: \"google-gemini-cli\",\n\t\t\tbaseUrl: \"https://cloudcode-pa.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"google-gemini-cli\">,\n\t\t\"gemini-2.5-pro\": {\n\t\t\tid: \"gemini-2.5-pro\",\n\t\t\tname: \"Gemini 2.5 Pro (Cloud Code Assist)\",\n\t\t\tapi: \"google-gemini-cli\",\n\t\t\tprovider: \"google-gemini-cli\",\n\t\t\tbaseUrl: \"https://cloudcode-pa.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"google-gemini-cli\">,\n\t\t\"gemini-3-flash-preview\": {\n\t\t\tid: \"gemini-3-flash-preview\",\n\t\t\tname: \"Gemini 3 Flash Preview (Cloud Code Assist)\",\n\t\t\tapi: \"google-gemini-cli\",\n\t\t\tprovider: \"google-gemini-cli\",\n\t\t\tbaseUrl: \"https://cloudcode-pa.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"google-gemini-cli\">,\n\t\t\"gemini-3-pro-preview\": {\n\t\t\tid: \"gemini-3-pro-preview\",\n\t\t\tname: \"Gemini 3 Pro Preview (Cloud Code Assist)\",\n\t\t\tapi: \"google-gemini-cli\",\n\t\t\tprovider: \"google-gemini-cli\",\n\t\t\tbaseUrl: \"https://cloudcode-pa.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"google-gemini-cli\">,\n\t},\n\t\"google-vertex\": {\n\t\t\"gemini-1.5-flash\": {\n\t\t\tid: \"gemini-1.5-flash\",\n\t\t\tname: \"Gemini 1.5 Flash (Vertex)\",\n\t\t\tapi: \"google-vertex\",\n\t\t\tprovider: \"google-vertex\",\n\t\t\tbaseUrl: \"https://{location}-aiplatform.googleapis.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.075,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0.01875,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"google-vertex\">,\n\t\t\"gemini-1.5-flash-8b\": {\n\t\t\tid: \"gemini-1.5-flash-8b\",\n\t\t\tname: \"Gemini 1.5 Flash-8B (Vertex)\",\n\t\t\tapi: \"google-vertex\",\n\t\t\tprovider: \"google-vertex\",\n\t\t\tbaseUrl: \"https://{location}-aiplatform.googleapis.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.0375,\n\t\t\t\toutput: 0.15,\n\t\t\t\tcacheRead: 0.01,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"google-vertex\">,\n\t\t\"gemini-1.5-pro\": {\n\t\t\tid: \"gemini-1.5-pro\",\n\t\t\tname: \"Gemini 1.5 Pro (Vertex)\",\n\t\t\tapi: \"google-vertex\",\n\t\t\tprovider: \"google-vertex\",\n\t\t\tbaseUrl: \"https://{location}-aiplatform.googleapis.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.3125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"google-vertex\">,\n\t\t\"gemini-2.0-flash\": {\n\t\t\tid: \"gemini-2.0-flash\",\n\t\t\tname: \"Gemini 2.0 Flash (Vertex)\",\n\t\t\tapi: \"google-vertex\",\n\t\t\tprovider: \"google-vertex\",\n\t\t\tbaseUrl: \"https://{location}-aiplatform.googleapis.com\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0.0375,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"google-vertex\">,\n\t\t\"gemini-2.0-flash-lite\": {\n\t\t\tid: \"gemini-2.0-flash-lite\",\n\t\t\tname: \"Gemini 2.0 Flash Lite (Vertex)\",\n\t\t\tapi: \"google-vertex\",\n\t\t\tprovider: \"google-vertex\",\n\t\t\tbaseUrl: \"https://{location}-aiplatform.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.075,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0.01875,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-vertex\">,\n\t\t\"gemini-2.5-flash\": {\n\t\t\tid: \"gemini-2.5-flash\",\n\t\t\tname: \"Gemini 2.5 Flash (Vertex)\",\n\t\t\tapi: \"google-vertex\",\n\t\t\tprovider: \"google-vertex\",\n\t\t\tbaseUrl: \"https://{location}-aiplatform.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-vertex\">,\n\t\t\"gemini-2.5-flash-lite\": {\n\t\t\tid: \"gemini-2.5-flash-lite\",\n\t\t\tname: \"Gemini 2.5 Flash Lite (Vertex)\",\n\t\t\tapi: \"google-vertex\",\n\t\t\tprovider: \"google-vertex\",\n\t\t\tbaseUrl: \"https://{location}-aiplatform.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0.01,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-vertex\">,\n\t\t\"gemini-2.5-flash-lite-preview-09-2025\": {\n\t\t\tid: \"gemini-2.5-flash-lite-preview-09-2025\",\n\t\t\tname: \"Gemini 2.5 Flash Lite Preview 09-25 (Vertex)\",\n\t\t\tapi: \"google-vertex\",\n\t\t\tprovider: \"google-vertex\",\n\t\t\tbaseUrl: \"https://{location}-aiplatform.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0.01,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-vertex\">,\n\t\t\"gemini-2.5-pro\": {\n\t\t\tid: \"gemini-2.5-pro\",\n\t\t\tname: \"Gemini 2.5 Pro (Vertex)\",\n\t\t\tapi: \"google-vertex\",\n\t\t\tprovider: \"google-vertex\",\n\t\t\tbaseUrl: \"https://{location}-aiplatform.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-vertex\">,\n\t\t\"gemini-3-flash-preview\": {\n\t\t\tid: \"gemini-3-flash-preview\",\n\t\t\tname: \"Gemini 3 Flash Preview (Vertex)\",\n\t\t\tapi: \"google-vertex\",\n\t\t\tprovider: \"google-vertex\",\n\t\t\tbaseUrl: \"https://{location}-aiplatform.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0.05,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-vertex\">,\n\t\t\"gemini-3-pro-preview\": {\n\t\t\tid: \"gemini-3-pro-preview\",\n\t\t\tname: \"Gemini 3 Pro Preview (Vertex)\",\n\t\t\tapi: \"google-vertex\",\n\t\t\tprovider: \"google-vertex\",\n\t\t\tbaseUrl: \"https://{location}-aiplatform.googleapis.com\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 12,\n\t\t\t\tcacheRead: 0.2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"google-vertex\">,\n\t},\n\t\"groq\": {\n\t\t\"deepseek-r1-distill-llama-70b\": {\n\t\t\tid: \"deepseek-r1-distill-llama-70b\",\n\t\t\tname: \"DeepSeek R1 Distill Llama 70B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.75,\n\t\t\t\toutput: 0.99,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"gemma2-9b-it\": {\n\t\t\tid: \"gemma2-9b-it\",\n\t\t\tname: \"Gemma 2 9B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 0.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8192,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"llama-3.1-8b-instant\": {\n\t\t\tid: \"llama-3.1-8b-instant\",\n\t\t\tname: \"Llama 3.1 8B Instant\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.05,\n\t\t\t\toutput: 0.08,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"llama-3.3-70b-versatile\": {\n\t\t\tid: \"llama-3.3-70b-versatile\",\n\t\t\tname: \"Llama 3.3 70B Versatile\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.59,\n\t\t\t\toutput: 0.79,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"llama3-70b-8192\": {\n\t\t\tid: \"llama3-70b-8192\",\n\t\t\tname: \"Llama 3 70B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.59,\n\t\t\t\toutput: 0.79,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8192,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"llama3-8b-8192\": {\n\t\t\tid: \"llama3-8b-8192\",\n\t\t\tname: \"Llama 3 8B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.05,\n\t\t\t\toutput: 0.08,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8192,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"meta-llama/llama-4-maverick-17b-128e-instruct\": {\n\t\t\tid: \"meta-llama/llama-4-maverick-17b-128e-instruct\",\n\t\t\tname: \"Llama 4 Maverick 17B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"meta-llama/llama-4-scout-17b-16e-instruct\": {\n\t\t\tid: \"meta-llama/llama-4-scout-17b-16e-instruct\",\n\t\t\tname: \"Llama 4 Scout 17B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.11,\n\t\t\t\toutput: 0.34,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistral-saba-24b\": {\n\t\t\tid: \"mistral-saba-24b\",\n\t\t\tname: \"Mistral Saba 24B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.79,\n\t\t\t\toutput: 0.79,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"moonshotai/kimi-k2-instruct\": {\n\t\t\tid: \"moonshotai/kimi-k2-instruct\",\n\t\t\tname: \"Kimi K2 Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"moonshotai/kimi-k2-instruct-0905\": {\n\t\t\tid: \"moonshotai/kimi-k2-instruct-0905\",\n\t\t\tname: \"Kimi K2 Instruct 0905\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-oss-120b\": {\n\t\t\tid: \"openai/gpt-oss-120b\",\n\t\t\tname: \"GPT OSS 120B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-oss-20b\": {\n\t\t\tid: \"openai/gpt-oss-20b\",\n\t\t\tname: \"GPT OSS 20B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.075,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen-qwq-32b\": {\n\t\t\tid: \"qwen-qwq-32b\",\n\t\t\tname: \"Qwen QwQ 32B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.29,\n\t\t\t\toutput: 0.39,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-32b\": {\n\t\t\tid: \"qwen/qwen3-32b\",\n\t\t\tname: \"Qwen3 32B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"groq\",\n\t\t\tbaseUrl: \"https://api.groq.com/openai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.29,\n\t\t\t\toutput: 0.59,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t},\n\t\"huggingface\": {\n\t\t\"MiniMaxAI/MiniMax-M2.1\": {\n\t\t\tid: \"MiniMaxAI/MiniMax-M2.1\",\n\t\t\tname: \"MiniMax-M2.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"MiniMaxAI/MiniMax-M2.5\": {\n\t\t\tid: \"MiniMaxAI/MiniMax-M2.5\",\n\t\t\tname: \"MiniMax-M2.5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"Qwen/Qwen3-235B-A22B-Thinking-2507\": {\n\t\t\tid: \"Qwen/Qwen3-235B-A22B-Thinking-2507\",\n\t\t\tname: \"Qwen3-235B-A22B-Thinking-2507\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"Qwen/Qwen3-Coder-480B-A35B-Instruct\": {\n\t\t\tid: \"Qwen/Qwen3-Coder-480B-A35B-Instruct\",\n\t\t\tname: \"Qwen3-Coder-480B-A35B-Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 66536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"Qwen/Qwen3-Coder-Next\": {\n\t\t\tid: \"Qwen/Qwen3-Coder-Next\",\n\t\t\tname: \"Qwen3-Coder-Next\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"Qwen/Qwen3-Next-80B-A3B-Instruct\": {\n\t\t\tid: \"Qwen/Qwen3-Next-80B-A3B-Instruct\",\n\t\t\tname: \"Qwen3-Next-80B-A3B-Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 66536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"Qwen/Qwen3-Next-80B-A3B-Thinking\": {\n\t\t\tid: \"Qwen/Qwen3-Next-80B-A3B-Thinking\",\n\t\t\tname: \"Qwen3-Next-80B-A3B-Thinking\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"Qwen/Qwen3.5-397B-A17B\": {\n\t\t\tid: \"Qwen/Qwen3.5-397B-A17B\",\n\t\t\tname: \"Qwen3.5-397B-A17B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 3.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"XiaomiMiMo/MiMo-V2-Flash\": {\n\t\t\tid: \"XiaomiMiMo/MiMo-V2-Flash\",\n\t\t\tname: \"MiMo-V2-Flash\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"deepseek-ai/DeepSeek-R1-0528\": {\n\t\t\tid: \"deepseek-ai/DeepSeek-R1-0528\",\n\t\t\tname: \"DeepSeek-R1-0528\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 163840,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"deepseek-ai/DeepSeek-V3.2\": {\n\t\t\tid: \"deepseek-ai/DeepSeek-V3.2\",\n\t\t\tname: \"DeepSeek-V3.2\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.28,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"moonshotai/Kimi-K2-Instruct\": {\n\t\t\tid: \"moonshotai/Kimi-K2-Instruct\",\n\t\t\tname: \"Kimi-K2-Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"moonshotai/Kimi-K2-Instruct-0905\": {\n\t\t\tid: \"moonshotai/Kimi-K2-Instruct-0905\",\n\t\t\tname: \"Kimi-K2-Instruct-0905\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"moonshotai/Kimi-K2-Thinking\": {\n\t\t\tid: \"moonshotai/Kimi-K2-Thinking\",\n\t\t\tname: \"Kimi-K2-Thinking\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0.15,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"moonshotai/Kimi-K2.5\": {\n\t\t\tid: \"moonshotai/Kimi-K2.5\",\n\t\t\tname: \"Kimi-K2.5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"zai-org/GLM-4.7\": {\n\t\t\tid: \"zai-org/GLM-4.7\",\n\t\t\tname: \"GLM-4.7\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.2,\n\t\t\t\tcacheRead: 0.11,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"zai-org/GLM-4.7-Flash\": {\n\t\t\tid: \"zai-org/GLM-4.7-Flash\",\n\t\t\tname: \"GLM-4.7-Flash\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"zai-org/GLM-5\": {\n\t\t\tid: \"zai-org/GLM-5\",\n\t\t\tname: \"GLM-5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"huggingface\",\n\t\t\tbaseUrl: \"https://router.huggingface.co/v1\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 3.2,\n\t\t\t\tcacheRead: 0.2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 202752,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t},\n\t\"kimi-coding\": {\n\t\t\"k2p5\": {\n\t\t\tid: \"k2p5\",\n\t\t\tname: \"Kimi K2.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"kimi-coding\",\n\t\t\tbaseUrl: \"https://api.kimi.com/coding\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"kimi-k2-thinking\": {\n\t\t\tid: \"kimi-k2-thinking\",\n\t\t\tname: \"Kimi K2 Thinking\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"kimi-coding\",\n\t\t\tbaseUrl: \"https://api.kimi.com/coding\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t},\n\t\"minimax\": {\n\t\t\"MiniMax-M2\": {\n\t\t\tid: \"MiniMax-M2\",\n\t\t\tname: \"MiniMax-M2\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"minimax\",\n\t\t\tbaseUrl: \"https://api.minimax.io/anthropic\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 196608,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"MiniMax-M2.1\": {\n\t\t\tid: \"MiniMax-M2.1\",\n\t\t\tname: \"MiniMax-M2.1\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"minimax\",\n\t\t\tbaseUrl: \"https://api.minimax.io/anthropic\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"MiniMax-M2.5\": {\n\t\t\tid: \"MiniMax-M2.5\",\n\t\t\tname: \"MiniMax-M2.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"minimax\",\n\t\t\tbaseUrl: \"https://api.minimax.io/anthropic\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0.375,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"MiniMax-M2.5-highspeed\": {\n\t\t\tid: \"MiniMax-M2.5-highspeed\",\n\t\t\tname: \"MiniMax-M2.5-highspeed\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"minimax\",\n\t\t\tbaseUrl: \"https://api.minimax.io/anthropic\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.4,\n\t\t\t\tcacheRead: 0.06,\n\t\t\t\tcacheWrite: 0.375,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t},\n\t\"minimax-cn\": {\n\t\t\"MiniMax-M2\": {\n\t\t\tid: \"MiniMax-M2\",\n\t\t\tname: \"MiniMax-M2\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"minimax-cn\",\n\t\t\tbaseUrl: \"https://api.minimaxi.com/anthropic\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 196608,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"MiniMax-M2.1\": {\n\t\t\tid: \"MiniMax-M2.1\",\n\t\t\tname: \"MiniMax-M2.1\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"minimax-cn\",\n\t\t\tbaseUrl: \"https://api.minimaxi.com/anthropic\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"MiniMax-M2.5\": {\n\t\t\tid: \"MiniMax-M2.5\",\n\t\t\tname: \"MiniMax-M2.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"minimax-cn\",\n\t\t\tbaseUrl: \"https://api.minimaxi.com/anthropic\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0.375,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"MiniMax-M2.5-highspeed\": {\n\t\t\tid: \"MiniMax-M2.5-highspeed\",\n\t\t\tname: \"MiniMax-M2.5-highspeed\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"minimax-cn\",\n\t\t\tbaseUrl: \"https://api.minimaxi.com/anthropic\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.4,\n\t\t\t\tcacheRead: 0.06,\n\t\t\t\tcacheWrite: 0.375,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t},\n\t\"mistral\": {\n\t\t\"codestral-latest\": {\n\t\t\tid: \"codestral-latest\",\n\t\t\tname: \"Codestral\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 0.9,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"devstral-2512\": {\n\t\t\tid: \"devstral-2512\",\n\t\t\tname: \"Devstral 2\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.4,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"devstral-medium-2507\": {\n\t\t\tid: \"devstral-medium-2507\",\n\t\t\tname: \"Devstral Medium\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.4,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"devstral-medium-latest\": {\n\t\t\tid: \"devstral-medium-latest\",\n\t\t\tname: \"Devstral 2\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.4,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"devstral-small-2505\": {\n\t\t\tid: \"devstral-small-2505\",\n\t\t\tname: \"Devstral Small 2505\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"devstral-small-2507\": {\n\t\t\tid: \"devstral-small-2507\",\n\t\t\tname: \"Devstral Small\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"labs-devstral-small-2512\": {\n\t\t\tid: \"labs-devstral-small-2512\",\n\t\t\tname: \"Devstral Small 2\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"magistral-medium-latest\": {\n\t\t\tid: \"magistral-medium-latest\",\n\t\t\tname: \"Magistral Medium\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"magistral-small\": {\n\t\t\tid: \"magistral-small\",\n\t\t\tname: \"Magistral Small\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"ministral-3b-latest\": {\n\t\t\tid: \"ministral-3b-latest\",\n\t\t\tname: \"Ministral 3B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.04,\n\t\t\t\toutput: 0.04,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"ministral-8b-latest\": {\n\t\t\tid: \"ministral-8b-latest\",\n\t\t\tname: \"Ministral 8B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistral-large-2411\": {\n\t\t\tid: \"mistral-large-2411\",\n\t\t\tname: \"Mistral Large 2.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistral-large-2512\": {\n\t\t\tid: \"mistral-large-2512\",\n\t\t\tname: \"Mistral Large 3\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistral-large-latest\": {\n\t\t\tid: \"mistral-large-latest\",\n\t\t\tname: \"Mistral Large\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistral-medium-2505\": {\n\t\t\tid: \"mistral-medium-2505\",\n\t\t\tname: \"Mistral Medium 3\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.4,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistral-medium-2508\": {\n\t\t\tid: \"mistral-medium-2508\",\n\t\t\tname: \"Mistral Medium 3.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.4,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistral-medium-latest\": {\n\t\t\tid: \"mistral-medium-latest\",\n\t\t\tname: \"Mistral Medium\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.4,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistral-nemo\": {\n\t\t\tid: \"mistral-nemo\",\n\t\t\tname: \"Mistral Nemo\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistral-small-2506\": {\n\t\t\tid: \"mistral-small-2506\",\n\t\t\tname: \"Mistral Small 3.2\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistral-small-latest\": {\n\t\t\tid: \"mistral-small-latest\",\n\t\t\tname: \"Mistral Small\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"open-mistral-7b\": {\n\t\t\tid: \"open-mistral-7b\",\n\t\t\tname: \"Mistral 7B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 0.25,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8000,\n\t\t\tmaxTokens: 8000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"open-mixtral-8x22b\": {\n\t\t\tid: \"open-mixtral-8x22b\",\n\t\t\tname: \"Mixtral 8x22B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 64000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"open-mixtral-8x7b\": {\n\t\t\tid: \"open-mixtral-8x7b\",\n\t\t\tname: \"Mixtral 8x7B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.7,\n\t\t\t\toutput: 0.7,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"pixtral-12b\": {\n\t\t\tid: \"pixtral-12b\",\n\t\t\tname: \"Pixtral 12B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"pixtral-large-latest\": {\n\t\t\tid: \"pixtral-large-latest\",\n\t\t\tname: \"Pixtral Large\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"mistral\",\n\t\t\tbaseUrl: \"https://api.mistral.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t},\n\t\"openai\": {\n\t\t\"codex-mini-latest\": {\n\t\t\tid: \"codex-mini-latest\",\n\t\t\tname: \"Codex Mini\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.5,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0.375,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-4\": {\n\t\t\tid: \"gpt-4\",\n\t\t\tname: \"GPT-4\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 30,\n\t\t\t\toutput: 60,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8192,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-4-turbo\": {\n\t\t\tid: \"gpt-4-turbo\",\n\t\t\tname: \"GPT-4 Turbo\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 10,\n\t\t\t\toutput: 30,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-4.1\": {\n\t\t\tid: \"gpt-4.1\",\n\t\t\tname: \"GPT-4.1\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1047576,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-4.1-mini\": {\n\t\t\tid: \"gpt-4.1-mini\",\n\t\t\tname: \"GPT-4.1 mini\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.4,\n\t\t\t\toutput: 1.6,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1047576,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-4.1-nano\": {\n\t\t\tid: \"gpt-4.1-nano\",\n\t\t\tname: \"GPT-4.1 nano\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.1,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1047576,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-4o\": {\n\t\t\tid: \"gpt-4o\",\n\t\t\tname: \"GPT-4o\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-4o-2024-05-13\": {\n\t\t\tid: \"gpt-4o-2024-05-13\",\n\t\t\tname: \"GPT-4o (2024-05-13)\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-4o-2024-08-06\": {\n\t\t\tid: \"gpt-4o-2024-08-06\",\n\t\t\tname: \"GPT-4o (2024-08-06)\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-4o-2024-11-20\": {\n\t\t\tid: \"gpt-4o-2024-11-20\",\n\t\t\tname: \"GPT-4o (2024-11-20)\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-4o-mini\": {\n\t\t\tid: \"gpt-4o-mini\",\n\t\t\tname: \"GPT-4o mini\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0.08,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5\": {\n\t\t\tid: \"gpt-5\",\n\t\t\tname: \"GPT-5\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5-chat-latest\": {\n\t\t\tid: \"gpt-5-chat-latest\",\n\t\t\tname: \"GPT-5 Chat Latest\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5-codex\": {\n\t\t\tid: \"gpt-5-codex\",\n\t\t\tname: \"GPT-5-Codex\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5-mini\": {\n\t\t\tid: \"gpt-5-mini\",\n\t\t\tname: \"GPT-5 Mini\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.025,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5-nano\": {\n\t\t\tid: \"gpt-5-nano\",\n\t\t\tname: \"GPT-5 Nano\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.05,\n\t\t\t\toutput: 0.4,\n\t\t\t\tcacheRead: 0.005,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5-pro\": {\n\t\t\tid: \"gpt-5-pro\",\n\t\t\tname: \"GPT-5 Pro\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 120,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 272000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1\": {\n\t\t\tid: \"gpt-5.1\",\n\t\t\tname: \"GPT-5.1\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.13,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1-chat-latest\": {\n\t\t\tid: \"gpt-5.1-chat-latest\",\n\t\t\tname: \"GPT-5.1 Chat\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1-codex\": {\n\t\t\tid: \"gpt-5.1-codex\",\n\t\t\tname: \"GPT-5.1 Codex\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1-codex-max\": {\n\t\t\tid: \"gpt-5.1-codex-max\",\n\t\t\tname: \"GPT-5.1 Codex Max\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1-codex-mini\": {\n\t\t\tid: \"gpt-5.1-codex-mini\",\n\t\t\tname: \"GPT-5.1 Codex mini\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.025,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.2\": {\n\t\t\tid: \"gpt-5.2\",\n\t\t\tname: \"GPT-5.2\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.2-chat-latest\": {\n\t\t\tid: \"gpt-5.2-chat-latest\",\n\t\t\tname: \"GPT-5.2 Chat\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.2-codex\": {\n\t\t\tid: \"gpt-5.2-codex\",\n\t\t\tname: \"GPT-5.2 Codex\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.2-pro\": {\n\t\t\tid: \"gpt-5.2-pro\",\n\t\t\tname: \"GPT-5.2 Pro\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 21,\n\t\t\t\toutput: 168,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.3-codex\": {\n\t\t\tid: \"gpt-5.3-codex\",\n\t\t\tname: \"GPT-5.3 Codex\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.3-codex-spark\": {\n\t\t\tid: \"gpt-5.3-codex-spark\",\n\t\t\tname: \"GPT-5.3 Codex Spark\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"o1\": {\n\t\t\tid: \"o1\",\n\t\t\tname: \"o1\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 60,\n\t\t\t\tcacheRead: 7.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"o1-pro\": {\n\t\t\tid: \"o1-pro\",\n\t\t\tname: \"o1-pro\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 150,\n\t\t\t\toutput: 600,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"o3\": {\n\t\t\tid: \"o3\",\n\t\t\tname: \"o3\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"o3-deep-research\": {\n\t\t\tid: \"o3-deep-research\",\n\t\t\tname: \"o3-deep-research\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 10,\n\t\t\t\toutput: 40,\n\t\t\t\tcacheRead: 2.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"o3-mini\": {\n\t\t\tid: \"o3-mini\",\n\t\t\tname: \"o3-mini\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.1,\n\t\t\t\toutput: 4.4,\n\t\t\t\tcacheRead: 0.55,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"o3-pro\": {\n\t\t\tid: \"o3-pro\",\n\t\t\tname: \"o3-pro\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 20,\n\t\t\t\toutput: 80,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"o4-mini\": {\n\t\t\tid: \"o4-mini\",\n\t\t\tname: \"o4-mini\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.1,\n\t\t\t\toutput: 4.4,\n\t\t\t\tcacheRead: 0.28,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"o4-mini-deep-research\": {\n\t\t\tid: \"o4-mini-deep-research\",\n\t\t\tname: \"o4-mini-deep-research\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"openai\",\n\t\t\tbaseUrl: \"https://api.openai.com/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t},\n\t\"openai-codex\": {\n\t\t\"gpt-5.1\": {\n\t\t\tid: \"gpt-5.1\",\n\t\t\tname: \"GPT-5.1\",\n\t\t\tapi: \"openai-codex-responses\",\n\t\t\tprovider: \"openai-codex\",\n\t\t\tbaseUrl: \"https://chatgpt.com/backend-api\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 272000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-codex-responses\">,\n\t\t\"gpt-5.1-codex-max\": {\n\t\t\tid: \"gpt-5.1-codex-max\",\n\t\t\tname: \"GPT-5.1 Codex Max\",\n\t\t\tapi: \"openai-codex-responses\",\n\t\t\tprovider: \"openai-codex\",\n\t\t\tbaseUrl: \"https://chatgpt.com/backend-api\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 272000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-codex-responses\">,\n\t\t\"gpt-5.1-codex-mini\": {\n\t\t\tid: \"gpt-5.1-codex-mini\",\n\t\t\tname: \"GPT-5.1 Codex Mini\",\n\t\t\tapi: \"openai-codex-responses\",\n\t\t\tprovider: \"openai-codex\",\n\t\t\tbaseUrl: \"https://chatgpt.com/backend-api\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.025,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 272000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-codex-responses\">,\n\t\t\"gpt-5.2\": {\n\t\t\tid: \"gpt-5.2\",\n\t\t\tname: \"GPT-5.2\",\n\t\t\tapi: \"openai-codex-responses\",\n\t\t\tprovider: \"openai-codex\",\n\t\t\tbaseUrl: \"https://chatgpt.com/backend-api\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 272000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-codex-responses\">,\n\t\t\"gpt-5.2-codex\": {\n\t\t\tid: \"gpt-5.2-codex\",\n\t\t\tname: \"GPT-5.2 Codex\",\n\t\t\tapi: \"openai-codex-responses\",\n\t\t\tprovider: \"openai-codex\",\n\t\t\tbaseUrl: \"https://chatgpt.com/backend-api\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 272000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-codex-responses\">,\n\t\t\"gpt-5.3-codex\": {\n\t\t\tid: \"gpt-5.3-codex\",\n\t\t\tname: \"GPT-5.3 Codex\",\n\t\t\tapi: \"openai-codex-responses\",\n\t\t\tprovider: \"openai-codex\",\n\t\t\tbaseUrl: \"https://chatgpt.com/backend-api\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 272000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-codex-responses\">,\n\t\t\"gpt-5.3-codex-spark\": {\n\t\t\tid: \"gpt-5.3-codex-spark\",\n\t\t\tname: \"GPT-5.3 Codex Spark\",\n\t\t\tapi: \"openai-codex-responses\",\n\t\t\tprovider: \"openai-codex\",\n\t\t\tbaseUrl: \"https://chatgpt.com/backend-api\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-codex-responses\">,\n\t},\n\t\"opencode\": {\n\t\t\"big-pickle\": {\n\t\t\tid: \"big-pickle\",\n\t\t\tname: \"Big Pickle\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"claude-3-5-haiku\": {\n\t\t\tid: \"claude-3-5-haiku\",\n\t\t\tname: \"Claude Haiku 3.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.8,\n\t\t\t\toutput: 4,\n\t\t\t\tcacheRead: 0.08,\n\t\t\t\tcacheWrite: 1,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-haiku-4-5\": {\n\t\t\tid: \"claude-haiku-4-5\",\n\t\t\tname: \"Claude Haiku 4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 1.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-opus-4-1\": {\n\t\t\tid: \"claude-opus-4-1\",\n\t\t\tname: \"Claude Opus 4.1\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-opus-4-5\": {\n\t\t\tid: \"claude-opus-4-5\",\n\t\t\tname: \"Claude Opus 4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-opus-4-6\": {\n\t\t\tid: \"claude-opus-4-6\",\n\t\t\tname: \"Claude Opus 4.6\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-sonnet-4\": {\n\t\t\tid: \"claude-sonnet-4\",\n\t\t\tname: \"Claude Sonnet 4\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"claude-sonnet-4-5\": {\n\t\t\tid: \"claude-sonnet-4-5\",\n\t\t\tname: \"Claude Sonnet 4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"gemini-3-flash\": {\n\t\t\tid: \"gemini-3-flash\",\n\t\t\tname: \"Gemini 3 Flash\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0.05,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"gemini-3-pro\": {\n\t\t\tid: \"gemini-3-pro\",\n\t\t\tname: \"Gemini 3 Pro\",\n\t\t\tapi: \"google-generative-ai\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 12,\n\t\t\t\tcacheRead: 0.2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"google-generative-ai\">,\n\t\t\"glm-4.6\": {\n\t\t\tid: \"glm-4.6\",\n\t\t\tname: \"GLM-4.6\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.2,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"glm-4.7\": {\n\t\t\tid: \"glm-4.7\",\n\t\t\tname: \"GLM-4.7\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.2,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"glm-5\": {\n\t\t\tid: \"glm-5\",\n\t\t\tname: \"GLM-5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 3.2,\n\t\t\t\tcacheRead: 0.2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"glm-5-free\": {\n\t\t\tid: \"glm-5-free\",\n\t\t\tname: \"GLM-5 Free\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"gpt-5\": {\n\t\t\tid: \"gpt-5\",\n\t\t\tname: \"GPT-5\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.07,\n\t\t\t\toutput: 8.5,\n\t\t\t\tcacheRead: 0.107,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5-codex\": {\n\t\t\tid: \"gpt-5-codex\",\n\t\t\tname: \"GPT-5 Codex\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.07,\n\t\t\t\toutput: 8.5,\n\t\t\t\tcacheRead: 0.107,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5-nano\": {\n\t\t\tid: \"gpt-5-nano\",\n\t\t\tname: \"GPT-5 Nano\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1\": {\n\t\t\tid: \"gpt-5.1\",\n\t\t\tname: \"GPT-5.1\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.07,\n\t\t\t\toutput: 8.5,\n\t\t\t\tcacheRead: 0.107,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1-codex\": {\n\t\t\tid: \"gpt-5.1-codex\",\n\t\t\tname: \"GPT-5.1 Codex\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.07,\n\t\t\t\toutput: 8.5,\n\t\t\t\tcacheRead: 0.107,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1-codex-max\": {\n\t\t\tid: \"gpt-5.1-codex-max\",\n\t\t\tname: \"GPT-5.1 Codex Max\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.1-codex-mini\": {\n\t\t\tid: \"gpt-5.1-codex-mini\",\n\t\t\tname: \"GPT-5.1 Codex Mini\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.025,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.2\": {\n\t\t\tid: \"gpt-5.2\",\n\t\t\tname: \"GPT-5.2\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"gpt-5.2-codex\": {\n\t\t\tid: \"gpt-5.2-codex\",\n\t\t\tname: \"GPT-5.2 Codex\",\n\t\t\tapi: \"openai-responses\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-responses\">,\n\t\t\"kimi-k2\": {\n\t\t\tid: \"kimi-k2\",\n\t\t\tname: \"Kimi K2\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.4,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0.4,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"kimi-k2-thinking\": {\n\t\t\tid: \"kimi-k2-thinking\",\n\t\t\tname: \"Kimi K2 Thinking\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.4,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0.4,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"kimi-k2.5\": {\n\t\t\tid: \"kimi-k2.5\",\n\t\t\tname: \"Kimi K2.5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0.08,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"kimi-k2.5-free\": {\n\t\t\tid: \"kimi-k2.5-free\",\n\t\t\tname: \"Kimi K2.5 Free\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"minimax-m2.1\": {\n\t\t\tid: \"minimax-m2.1\",\n\t\t\tname: \"MiniMax M2.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0.1,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"minimax-m2.5\": {\n\t\t\tid: \"minimax-m2.5\",\n\t\t\tname: \"MiniMax M2.5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0.06,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"minimax-m2.5-free\": {\n\t\t\tid: \"minimax-m2.5-free\",\n\t\t\tname: \"MiniMax M2.5 Free\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"opencode\",\n\t\t\tbaseUrl: \"https://opencode.ai/zen/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t},\n\t\"openrouter\": {\n\t\t\"ai21/jamba-large-1.7\": {\n\t\t\tid: \"ai21/jamba-large-1.7\",\n\t\t\tname: \"AI21: Jamba Large 1.7\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"alibaba/tongyi-deepresearch-30b-a3b\": {\n\t\t\tid: \"alibaba/tongyi-deepresearch-30b-a3b\",\n\t\t\tname: \"Tongyi DeepResearch 30B A3B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09,\n\t\t\t\toutput: 0.44999999999999996,\n\t\t\t\tcacheRead: 0.09,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"allenai/olmo-3.1-32b-instruct\": {\n\t\t\tid: \"allenai/olmo-3.1-32b-instruct\",\n\t\t\tname: \"AllenAI: Olmo 3.1 32B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 65536,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"amazon/nova-2-lite-v1\": {\n\t\t\tid: \"amazon/nova-2-lite-v1\",\n\t\t\tname: \"Amazon: Nova 2 Lite\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"amazon/nova-lite-v1\": {\n\t\t\tid: \"amazon/nova-lite-v1\",\n\t\t\tname: \"Amazon: Nova Lite 1.0\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.06,\n\t\t\t\toutput: 0.24,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 300000,\n\t\t\tmaxTokens: 5120,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"amazon/nova-micro-v1\": {\n\t\t\tid: \"amazon/nova-micro-v1\",\n\t\t\tname: \"Amazon: Nova Micro 1.0\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.035,\n\t\t\t\toutput: 0.14,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 5120,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"amazon/nova-premier-v1\": {\n\t\t\tid: \"amazon/nova-premier-v1\",\n\t\t\tname: \"Amazon: Nova Premier 1.0\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 12.5,\n\t\t\t\tcacheRead: 0.625,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"amazon/nova-pro-v1\": {\n\t\t\tid: \"amazon/nova-pro-v1\",\n\t\t\tname: \"Amazon: Nova Pro 1.0\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.7999999999999999,\n\t\t\t\toutput: 3.1999999999999997,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 300000,\n\t\t\tmaxTokens: 5120,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-3-haiku\": {\n\t\t\tid: \"anthropic/claude-3-haiku\",\n\t\t\tname: \"Anthropic: Claude 3 Haiku\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 1.25,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0.3,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-3.5-haiku\": {\n\t\t\tid: \"anthropic/claude-3.5-haiku\",\n\t\t\tname: \"Anthropic: Claude 3.5 Haiku\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.7999999999999999,\n\t\t\t\toutput: 4,\n\t\t\t\tcacheRead: 0.08,\n\t\t\t\tcacheWrite: 1,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-3.5-sonnet\": {\n\t\t\tid: \"anthropic/claude-3.5-sonnet\",\n\t\t\tname: \"Anthropic: Claude 3.5 Sonnet\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 6,\n\t\t\t\toutput: 30,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-3.7-sonnet\": {\n\t\t\tid: \"anthropic/claude-3.7-sonnet\",\n\t\t\tname: \"Anthropic: Claude 3.7 Sonnet\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-3.7-sonnet:thinking\": {\n\t\t\tid: \"anthropic/claude-3.7-sonnet:thinking\",\n\t\t\tname: \"Anthropic: Claude 3.7 Sonnet (thinking)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-haiku-4.5\": {\n\t\t\tid: \"anthropic/claude-haiku-4.5\",\n\t\t\tname: \"Anthropic: Claude Haiku 4.5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.09999999999999999,\n\t\t\t\tcacheWrite: 1.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-opus-4\": {\n\t\t\tid: \"anthropic/claude-opus-4\",\n\t\t\tname: \"Anthropic: Claude Opus 4\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-opus-4.1\": {\n\t\t\tid: \"anthropic/claude-opus-4.1\",\n\t\t\tname: \"Anthropic: Claude Opus 4.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-opus-4.5\": {\n\t\t\tid: \"anthropic/claude-opus-4.5\",\n\t\t\tname: \"Anthropic: Claude Opus 4.5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-opus-4.6\": {\n\t\t\tid: \"anthropic/claude-opus-4.6\",\n\t\t\tname: \"Anthropic: Claude Opus 4.6\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-sonnet-4\": {\n\t\t\tid: \"anthropic/claude-sonnet-4\",\n\t\t\tname: \"Anthropic: Claude Sonnet 4\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-sonnet-4.5\": {\n\t\t\tid: \"anthropic/claude-sonnet-4.5\",\n\t\t\tname: \"Anthropic: Claude Sonnet 4.5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"anthropic/claude-sonnet-4.6\": {\n\t\t\tid: \"anthropic/claude-sonnet-4.6\",\n\t\t\tname: \"Anthropic: Claude Sonnet 4.6\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"arcee-ai/trinity-large-preview:free\": {\n\t\t\tid: \"arcee-ai/trinity-large-preview:free\",\n\t\t\tname: \"Arcee AI: Trinity Large Preview (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"arcee-ai/trinity-mini\": {\n\t\t\tid: \"arcee-ai/trinity-mini\",\n\t\t\tname: \"Arcee AI: Trinity Mini\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.045,\n\t\t\t\toutput: 0.15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"arcee-ai/trinity-mini:free\": {\n\t\t\tid: \"arcee-ai/trinity-mini:free\",\n\t\t\tname: \"Arcee AI: Trinity Mini (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"arcee-ai/virtuoso-large\": {\n\t\t\tid: \"arcee-ai/virtuoso-large\",\n\t\t\tname: \"Arcee AI: Virtuoso Large\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.75,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"auto\": {\n\t\t\tid: \"auto\",\n\t\t\tname: \"Auto\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 2000000,\n\t\t\tmaxTokens: 30000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"baidu/ernie-4.5-21b-a3b\": {\n\t\t\tid: \"baidu/ernie-4.5-21b-a3b\",\n\t\t\tname: \"Baidu: ERNIE 4.5 21B A3B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.07,\n\t\t\t\toutput: 0.28,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 120000,\n\t\t\tmaxTokens: 8000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"baidu/ernie-4.5-vl-28b-a3b\": {\n\t\t\tid: \"baidu/ernie-4.5-vl-28b-a3b\",\n\t\t\tname: \"Baidu: ERNIE 4.5 VL 28B A3B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.14,\n\t\t\t\toutput: 0.56,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 30000,\n\t\t\tmaxTokens: 8000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"bytedance-seed/seed-1.6\": {\n\t\t\tid: \"bytedance-seed/seed-1.6\",\n\t\t\tname: \"ByteDance Seed: Seed 1.6\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"bytedance-seed/seed-1.6-flash\": {\n\t\t\tid: \"bytedance-seed/seed-1.6-flash\",\n\t\t\tname: \"ByteDance Seed: Seed 1.6 Flash\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.075,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"cohere/command-r-08-2024\": {\n\t\t\tid: \"cohere/command-r-08-2024\",\n\t\t\tname: \"Cohere: Command R (08-2024)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"cohere/command-r-plus-08-2024\": {\n\t\t\tid: \"cohere/command-r-plus-08-2024\",\n\t\t\tname: \"Cohere: Command R+ (08-2024)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"deepseek/deepseek-chat\": {\n\t\t\tid: \"deepseek/deepseek-chat\",\n\t\t\tname: \"DeepSeek: DeepSeek V3\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0.15,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 163840,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"deepseek/deepseek-chat-v3-0324\": {\n\t\t\tid: \"deepseek/deepseek-chat-v3-0324\",\n\t\t\tname: \"DeepSeek: DeepSeek V3 0324\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19,\n\t\t\t\toutput: 0.87,\n\t\t\t\tcacheRead: 0.095,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"deepseek/deepseek-chat-v3.1\": {\n\t\t\tid: \"deepseek/deepseek-chat-v3.1\",\n\t\t\tname: \"DeepSeek: DeepSeek V3.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.75,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 7168,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"deepseek/deepseek-r1\": {\n\t\t\tid: \"deepseek/deepseek-r1\",\n\t\t\tname: \"DeepSeek: R1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.7,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 64000,\n\t\t\tmaxTokens: 16000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"deepseek/deepseek-r1-0528\": {\n\t\t\tid: \"deepseek/deepseek-r1-0528\",\n\t\t\tname: \"DeepSeek: R1 0528\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 1.75,\n\t\t\t\tcacheRead: 0.19999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"deepseek/deepseek-v3.1-terminus\": {\n\t\t\tid: \"deepseek/deepseek-v3.1-terminus\",\n\t\t\tname: \"DeepSeek: DeepSeek V3.1 Terminus\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.21,\n\t\t\t\toutput: 0.7899999999999999,\n\t\t\t\tcacheRead: 0.1300000002,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"deepseek/deepseek-v3.1-terminus:exacto\": {\n\t\t\tid: \"deepseek/deepseek-v3.1-terminus:exacto\",\n\t\t\tname: \"DeepSeek: DeepSeek V3.1 Terminus (exacto)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.21,\n\t\t\t\toutput: 0.7899999999999999,\n\t\t\t\tcacheRead: 0.16799999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"deepseek/deepseek-v3.2\": {\n\t\t\tid: \"deepseek/deepseek-v3.2\",\n\t\t\tname: \"DeepSeek: DeepSeek V3.2\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.26,\n\t\t\t\toutput: 0.38,\n\t\t\t\tcacheRead: 0.13,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"deepseek/deepseek-v3.2-exp\": {\n\t\t\tid: \"deepseek/deepseek-v3.2-exp\",\n\t\t\tname: \"DeepSeek: DeepSeek V3.2 Exp\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.27,\n\t\t\t\toutput: 0.41,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemini-2.0-flash-001\": {\n\t\t\tid: \"google/gemini-2.0-flash-001\",\n\t\t\tname: \"Google: Gemini 2.0 Flash\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0.024999999999999998,\n\t\t\t\tcacheWrite: 0.08333333333333334,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemini-2.0-flash-lite-001\": {\n\t\t\tid: \"google/gemini-2.0-flash-lite-001\",\n\t\t\tname: \"Google: Gemini 2.0 Flash Lite\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.075,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemini-2.5-flash\": {\n\t\t\tid: \"google/gemini-2.5-flash\",\n\t\t\tname: \"Google: Gemini 2.5 Flash\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0.08333333333333334,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemini-2.5-flash-lite\": {\n\t\t\tid: \"google/gemini-2.5-flash-lite\",\n\t\t\tname: \"Google: Gemini 2.5 Flash Lite\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0.01,\n\t\t\t\tcacheWrite: 0.08333333333333334,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemini-2.5-flash-lite-preview-09-2025\": {\n\t\t\tid: \"google/gemini-2.5-flash-lite-preview-09-2025\",\n\t\t\tname: \"Google: Gemini 2.5 Flash Lite Preview 09-2025\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0.01,\n\t\t\t\tcacheWrite: 0.08333333333333334,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemini-2.5-flash-preview-09-2025\": {\n\t\t\tid: \"google/gemini-2.5-flash-preview-09-2025\",\n\t\t\tname: \"Google: Gemini 2.5 Flash Preview 09-2025\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0.08333333333333334,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemini-2.5-pro\": {\n\t\t\tid: \"google/gemini-2.5-pro\",\n\t\t\tname: \"Google: Gemini 2.5 Pro\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0.375,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemini-2.5-pro-preview\": {\n\t\t\tid: \"google/gemini-2.5-pro-preview\",\n\t\t\tname: \"Google: Gemini 2.5 Pro Preview 06-05\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0.375,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemini-2.5-pro-preview-05-06\": {\n\t\t\tid: \"google/gemini-2.5-pro-preview-05-06\",\n\t\t\tname: \"Google: Gemini 2.5 Pro Preview 05-06\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0.375,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemini-3-flash-preview\": {\n\t\t\tid: \"google/gemini-3-flash-preview\",\n\t\t\tname: \"Google: Gemini 3 Flash Preview\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0.049999999999999996,\n\t\t\t\tcacheWrite: 0.08333333333333334,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemini-3-pro-preview\": {\n\t\t\tid: \"google/gemini-3-pro-preview\",\n\t\t\tname: \"Google: Gemini 3 Pro Preview\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 12,\n\t\t\t\tcacheRead: 0.19999999999999998,\n\t\t\t\tcacheWrite: 0.375,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemma-3-27b-it\": {\n\t\t\tid: \"google/gemma-3-27b-it\",\n\t\t\tname: \"Google: Gemma 3 27B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.04,\n\t\t\t\toutput: 0.15,\n\t\t\t\tcacheRead: 0.02,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"google/gemma-3-27b-it:free\": {\n\t\t\tid: \"google/gemma-3-27b-it:free\",\n\t\t\tname: \"Google: Gemma 3 27B (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"inception/mercury\": {\n\t\t\tid: \"inception/mercury\",\n\t\t\tname: \"Inception: Mercury\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"inception/mercury-coder\": {\n\t\t\tid: \"inception/mercury-coder\",\n\t\t\tname: \"Inception: Mercury Coder\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"kwaipilot/kat-coder-pro\": {\n\t\t\tid: \"kwaipilot/kat-coder-pro\",\n\t\t\tname: \"Kwaipilot: KAT-Coder-Pro V1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.207,\n\t\t\t\toutput: 0.828,\n\t\t\t\tcacheRead: 0.0414,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"meta-llama/llama-3-8b-instruct\": {\n\t\t\tid: \"meta-llama/llama-3-8b-instruct\",\n\t\t\tname: \"Meta: Llama 3 8B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.03,\n\t\t\t\toutput: 0.04,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8192,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"meta-llama/llama-3.1-405b-instruct\": {\n\t\t\tid: \"meta-llama/llama-3.1-405b-instruct\",\n\t\t\tname: \"Meta: Llama 3.1 405B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 4,\n\t\t\t\toutput: 4,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"meta-llama/llama-3.1-70b-instruct\": {\n\t\t\tid: \"meta-llama/llama-3.1-70b-instruct\",\n\t\t\tname: \"Meta: Llama 3.1 70B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"meta-llama/llama-3.1-8b-instruct\": {\n\t\t\tid: \"meta-llama/llama-3.1-8b-instruct\",\n\t\t\tname: \"Meta: Llama 3.1 8B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.02,\n\t\t\t\toutput: 0.049999999999999996,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 16384,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"meta-llama/llama-3.3-70b-instruct\": {\n\t\t\tid: \"meta-llama/llama-3.3-70b-instruct\",\n\t\t\tname: \"Meta: Llama 3.3 70B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.32,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"meta-llama/llama-3.3-70b-instruct:free\": {\n\t\t\tid: \"meta-llama/llama-3.3-70b-instruct:free\",\n\t\t\tname: \"Meta: Llama 3.3 70B Instruct (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"meta-llama/llama-4-maverick\": {\n\t\t\tid: \"meta-llama/llama-4-maverick\",\n\t\t\tname: \"Meta: Llama 4 Maverick\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"meta-llama/llama-4-scout\": {\n\t\t\tid: \"meta-llama/llama-4-scout\",\n\t\t\tname: \"Meta: Llama 4 Scout\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.08,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 327680,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"minimax/minimax-m1\": {\n\t\t\tid: \"minimax/minimax-m1\",\n\t\t\tname: \"MiniMax: MiniMax M1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 2.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 40000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"minimax/minimax-m2\": {\n\t\t\tid: \"minimax/minimax-m2\",\n\t\t\tname: \"MiniMax: MiniMax M2\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.255,\n\t\t\t\toutput: 1,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 196608,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"minimax/minimax-m2.1\": {\n\t\t\tid: \"minimax/minimax-m2.1\",\n\t\t\tname: \"MiniMax: MiniMax M2.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.27,\n\t\t\t\toutput: 0.95,\n\t\t\t\tcacheRead: 0.0299999997,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 196608,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"minimax/minimax-m2.5\": {\n\t\t\tid: \"minimax/minimax-m2.5\",\n\t\t\tname: \"MiniMax: MiniMax M2.5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.1,\n\t\t\t\tcacheRead: 0.15,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 196608,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/codestral-2508\": {\n\t\t\tid: \"mistralai/codestral-2508\",\n\t\t\tname: \"Mistral: Codestral 2508\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 0.8999999999999999,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/devstral-2512\": {\n\t\t\tid: \"mistralai/devstral-2512\",\n\t\t\tname: \"Mistral: Devstral 2 2512\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.049999999999999996,\n\t\t\t\toutput: 0.22,\n\t\t\t\tcacheRead: 0.024999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/devstral-medium\": {\n\t\t\tid: \"mistralai/devstral-medium\",\n\t\t\tname: \"Mistral: Devstral Medium\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/devstral-small\": {\n\t\t\tid: \"mistralai/devstral-small\",\n\t\t\tname: \"Mistral: Devstral Small 1.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/ministral-14b-2512\": {\n\t\t\tid: \"mistralai/ministral-14b-2512\",\n\t\t\tname: \"Mistral: Ministral 3 14B 2512\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 0.19999999999999998,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/ministral-3b-2512\": {\n\t\t\tid: \"mistralai/ministral-3b-2512\",\n\t\t\tname: \"Mistral: Ministral 3 3B 2512\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.09999999999999999,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/ministral-8b-2512\": {\n\t\t\tid: \"mistralai/ministral-8b-2512\",\n\t\t\tname: \"Mistral: Ministral 3 8B 2512\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-large\": {\n\t\t\tid: \"mistralai/mistral-large\",\n\t\t\tname: \"Mistral Large\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-large-2407\": {\n\t\t\tid: \"mistralai/mistral-large-2407\",\n\t\t\tname: \"Mistral Large 2407\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-large-2411\": {\n\t\t\tid: \"mistralai/mistral-large-2411\",\n\t\t\tname: \"Mistral Large 2411\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-large-2512\": {\n\t\t\tid: \"mistralai/mistral-large-2512\",\n\t\t\tname: \"Mistral: Mistral Large 3 2512\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-medium-3\": {\n\t\t\tid: \"mistralai/mistral-medium-3\",\n\t\t\tname: \"Mistral: Mistral Medium 3\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-medium-3.1\": {\n\t\t\tid: \"mistralai/mistral-medium-3.1\",\n\t\t\tname: \"Mistral: Mistral Medium 3.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-nemo\": {\n\t\t\tid: \"mistralai/mistral-nemo\",\n\t\t\tname: \"Mistral: Mistral Nemo\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.02,\n\t\t\t\toutput: 0.04,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-saba\": {\n\t\t\tid: \"mistralai/mistral-saba\",\n\t\t\tname: \"Mistral: Saba\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-small-24b-instruct-2501\": {\n\t\t\tid: \"mistralai/mistral-small-24b-instruct-2501\",\n\t\t\tname: \"Mistral: Mistral Small 3\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.049999999999999996,\n\t\t\t\toutput: 0.08,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-small-3.1-24b-instruct\": {\n\t\t\tid: \"mistralai/mistral-small-3.1-24b-instruct\",\n\t\t\tname: \"Mistral: Mistral Small 3.1 24B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.03,\n\t\t\t\toutput: 0.11,\n\t\t\t\tcacheRead: 0.015,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-small-3.1-24b-instruct:free\": {\n\t\t\tid: \"mistralai/mistral-small-3.1-24b-instruct:free\",\n\t\t\tname: \"Mistral: Mistral Small 3.1 24B (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-small-3.2-24b-instruct\": {\n\t\t\tid: \"mistralai/mistral-small-3.2-24b-instruct\",\n\t\t\tname: \"Mistral: Mistral Small 3.2 24B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.06,\n\t\t\t\toutput: 0.18,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mistral-small-creative\": {\n\t\t\tid: \"mistralai/mistral-small-creative\",\n\t\t\tname: \"Mistral: Mistral Small Creative\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mixtral-8x22b-instruct\": {\n\t\t\tid: \"mistralai/mixtral-8x22b-instruct\",\n\t\t\tname: \"Mistral: Mixtral 8x22B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 65536,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/mixtral-8x7b-instruct\": {\n\t\t\tid: \"mistralai/mixtral-8x7b-instruct\",\n\t\t\tname: \"Mistral: Mixtral 8x7B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.54,\n\t\t\t\toutput: 0.54,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/pixtral-large-2411\": {\n\t\t\tid: \"mistralai/pixtral-large-2411\",\n\t\t\tname: \"Mistral: Pixtral Large 2411\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"mistralai/voxtral-small-24b-2507\": {\n\t\t\tid: \"mistralai/voxtral-small-24b-2507\",\n\t\t\tname: \"Mistral: Voxtral Small 24B 2507\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"moonshotai/kimi-k2\": {\n\t\t\tid: \"moonshotai/kimi-k2\",\n\t\t\tname: \"MoonshotAI: Kimi K2 0711\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 2.4,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"moonshotai/kimi-k2-0905\": {\n\t\t\tid: \"moonshotai/kimi-k2-0905\",\n\t\t\tname: \"MoonshotAI: Kimi K2 0905\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.15,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"moonshotai/kimi-k2-0905:exacto\": {\n\t\t\tid: \"moonshotai/kimi-k2-0905:exacto\",\n\t\t\tname: \"MoonshotAI: Kimi K2 0905 (exacto)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"moonshotai/kimi-k2-thinking\": {\n\t\t\tid: \"moonshotai/kimi-k2-thinking\",\n\t\t\tname: \"MoonshotAI: Kimi K2 Thinking\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 1.75,\n\t\t\t\tcacheRead: 0.19999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"moonshotai/kimi-k2.5\": {\n\t\t\tid: \"moonshotai/kimi-k2.5\",\n\t\t\tname: \"MoonshotAI: Kimi K2.5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.22999999999999998,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"nex-agi/deepseek-v3.1-nex-n1\": {\n\t\t\tid: \"nex-agi/deepseek-v3.1-nex-n1\",\n\t\t\tname: \"Nex AGI: DeepSeek V3.1 Nex N1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.27,\n\t\t\t\toutput: 1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 163840,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"nousresearch/deephermes-3-mistral-24b-preview\": {\n\t\t\tid: \"nousresearch/deephermes-3-mistral-24b-preview\",\n\t\t\tname: \"Nous: DeepHermes 3 Mistral 24B Preview\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.02,\n\t\t\t\toutput: 0.09999999999999999,\n\t\t\t\tcacheRead: 0.01,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"nousresearch/hermes-4-70b\": {\n\t\t\tid: \"nousresearch/hermes-4-70b\",\n\t\t\tname: \"Nous: Hermes 4 70B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.11,\n\t\t\t\toutput: 0.38,\n\t\t\t\tcacheRead: 0.055,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"nvidia/llama-3.1-nemotron-70b-instruct\": {\n\t\t\tid: \"nvidia/llama-3.1-nemotron-70b-instruct\",\n\t\t\tname: \"NVIDIA: Llama 3.1 Nemotron 70B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.2,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"nvidia/llama-3.3-nemotron-super-49b-v1.5\": {\n\t\t\tid: \"nvidia/llama-3.3-nemotron-super-49b-v1.5\",\n\t\t\tname: \"NVIDIA: Llama 3.3 Nemotron Super 49B V1.5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"nvidia/nemotron-3-nano-30b-a3b\": {\n\t\t\tid: \"nvidia/nemotron-3-nano-30b-a3b\",\n\t\t\tname: \"NVIDIA: Nemotron 3 Nano 30B A3B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.049999999999999996,\n\t\t\t\toutput: 0.19999999999999998,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"nvidia/nemotron-3-nano-30b-a3b:free\": {\n\t\t\tid: \"nvidia/nemotron-3-nano-30b-a3b:free\",\n\t\t\tname: \"NVIDIA: Nemotron 3 Nano 30B A3B (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"nvidia/nemotron-nano-12b-v2-vl:free\": {\n\t\t\tid: \"nvidia/nemotron-nano-12b-v2-vl:free\",\n\t\t\tname: \"NVIDIA: Nemotron Nano 12B 2 VL (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"nvidia/nemotron-nano-9b-v2\": {\n\t\t\tid: \"nvidia/nemotron-nano-9b-v2\",\n\t\t\tname: \"NVIDIA: Nemotron Nano 9B V2\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.04,\n\t\t\t\toutput: 0.16,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"nvidia/nemotron-nano-9b-v2:free\": {\n\t\t\tid: \"nvidia/nemotron-nano-9b-v2:free\",\n\t\t\tname: \"NVIDIA: Nemotron Nano 9B V2 (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-3.5-turbo\": {\n\t\t\tid: \"openai/gpt-3.5-turbo\",\n\t\t\tname: \"OpenAI: GPT-3.5 Turbo\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 16385,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-3.5-turbo-0613\": {\n\t\t\tid: \"openai/gpt-3.5-turbo-0613\",\n\t\t\tname: \"OpenAI: GPT-3.5 Turbo (older v0613)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 4095,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-3.5-turbo-16k\": {\n\t\t\tid: \"openai/gpt-3.5-turbo-16k\",\n\t\t\tname: \"OpenAI: GPT-3.5 Turbo 16k\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 4,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 16385,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4\": {\n\t\t\tid: \"openai/gpt-4\",\n\t\t\tname: \"OpenAI: GPT-4\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 30,\n\t\t\t\toutput: 60,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8191,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4-0314\": {\n\t\t\tid: \"openai/gpt-4-0314\",\n\t\t\tname: \"OpenAI: GPT-4 (older v0314)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 30,\n\t\t\t\toutput: 60,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8191,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4-1106-preview\": {\n\t\t\tid: \"openai/gpt-4-1106-preview\",\n\t\t\tname: \"OpenAI: GPT-4 Turbo (older v1106)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 10,\n\t\t\t\toutput: 30,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4-turbo\": {\n\t\t\tid: \"openai/gpt-4-turbo\",\n\t\t\tname: \"OpenAI: GPT-4 Turbo\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 10,\n\t\t\t\toutput: 30,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4-turbo-preview\": {\n\t\t\tid: \"openai/gpt-4-turbo-preview\",\n\t\t\tname: \"OpenAI: GPT-4 Turbo Preview\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 10,\n\t\t\t\toutput: 30,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4.1\": {\n\t\t\tid: \"openai/gpt-4.1\",\n\t\t\tname: \"OpenAI: GPT-4.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1047576,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4.1-mini\": {\n\t\t\tid: \"openai/gpt-4.1-mini\",\n\t\t\tname: \"OpenAI: GPT-4.1 Mini\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 1.5999999999999999,\n\t\t\t\tcacheRead: 0.09999999999999999,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1047576,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4.1-nano\": {\n\t\t\tid: \"openai/gpt-4.1-nano\",\n\t\t\tname: \"OpenAI: GPT-4.1 Nano\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0.024999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1047576,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4o\": {\n\t\t\tid: \"openai/gpt-4o\",\n\t\t\tname: \"OpenAI: GPT-4o\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4o-2024-05-13\": {\n\t\t\tid: \"openai/gpt-4o-2024-05-13\",\n\t\t\tname: \"OpenAI: GPT-4o (2024-05-13)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4o-2024-08-06\": {\n\t\t\tid: \"openai/gpt-4o-2024-08-06\",\n\t\t\tname: \"OpenAI: GPT-4o (2024-08-06)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4o-2024-11-20\": {\n\t\t\tid: \"openai/gpt-4o-2024-11-20\",\n\t\t\tname: \"OpenAI: GPT-4o (2024-11-20)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4o-audio-preview\": {\n\t\t\tid: \"openai/gpt-4o-audio-preview\",\n\t\t\tname: \"OpenAI: GPT-4o Audio\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4o-mini\": {\n\t\t\tid: \"openai/gpt-4o-mini\",\n\t\t\tname: \"OpenAI: GPT-4o-mini\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0.075,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4o-mini-2024-07-18\": {\n\t\t\tid: \"openai/gpt-4o-mini-2024-07-18\",\n\t\t\tname: \"OpenAI: GPT-4o-mini (2024-07-18)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0.075,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-4o:extended\": {\n\t\t\tid: \"openai/gpt-4o:extended\",\n\t\t\tname: \"OpenAI: GPT-4o (extended)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 6,\n\t\t\t\toutput: 18,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5\": {\n\t\t\tid: \"openai/gpt-5\",\n\t\t\tname: \"OpenAI: GPT-5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5-codex\": {\n\t\t\tid: \"openai/gpt-5-codex\",\n\t\t\tname: \"OpenAI: GPT-5 Codex\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5-image\": {\n\t\t\tid: \"openai/gpt-5-image\",\n\t\t\tname: \"OpenAI: GPT-5 Image\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 10,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5-image-mini\": {\n\t\t\tid: \"openai/gpt-5-image-mini\",\n\t\t\tname: \"OpenAI: GPT-5 Image Mini\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5-mini\": {\n\t\t\tid: \"openai/gpt-5-mini\",\n\t\t\tname: \"OpenAI: GPT-5 Mini\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.024999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5-nano\": {\n\t\t\tid: \"openai/gpt-5-nano\",\n\t\t\tname: \"OpenAI: GPT-5 Nano\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.049999999999999996,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0.005,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5-pro\": {\n\t\t\tid: \"openai/gpt-5-pro\",\n\t\t\tname: \"OpenAI: GPT-5 Pro\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 120,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5.1\": {\n\t\t\tid: \"openai/gpt-5.1\",\n\t\t\tname: \"OpenAI: GPT-5.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5.1-chat\": {\n\t\t\tid: \"openai/gpt-5.1-chat\",\n\t\t\tname: \"OpenAI: GPT-5.1 Chat\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5.1-codex\": {\n\t\t\tid: \"openai/gpt-5.1-codex\",\n\t\t\tname: \"OpenAI: GPT-5.1-Codex\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5.1-codex-max\": {\n\t\t\tid: \"openai/gpt-5.1-codex-max\",\n\t\t\tname: \"OpenAI: GPT-5.1-Codex-Max\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5.1-codex-mini\": {\n\t\t\tid: \"openai/gpt-5.1-codex-mini\",\n\t\t\tname: \"OpenAI: GPT-5.1-Codex-Mini\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.024999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5.2\": {\n\t\t\tid: \"openai/gpt-5.2\",\n\t\t\tname: \"OpenAI: GPT-5.2\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5.2-chat\": {\n\t\t\tid: \"openai/gpt-5.2-chat\",\n\t\t\tname: \"OpenAI: GPT-5.2 Chat\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5.2-codex\": {\n\t\t\tid: \"openai/gpt-5.2-codex\",\n\t\t\tname: \"OpenAI: GPT-5.2-Codex\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-5.2-pro\": {\n\t\t\tid: \"openai/gpt-5.2-pro\",\n\t\t\tname: \"OpenAI: GPT-5.2 Pro\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 21,\n\t\t\t\toutput: 168,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-oss-120b\": {\n\t\t\tid: \"openai/gpt-oss-120b\",\n\t\t\tname: \"OpenAI: gpt-oss-120b\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.039,\n\t\t\t\toutput: 0.19,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-oss-120b:exacto\": {\n\t\t\tid: \"openai/gpt-oss-120b:exacto\",\n\t\t\tname: \"OpenAI: gpt-oss-120b (exacto)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.039,\n\t\t\t\toutput: 0.19,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-oss-120b:free\": {\n\t\t\tid: \"openai/gpt-oss-120b:free\",\n\t\t\tname: \"OpenAI: gpt-oss-120b (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-oss-20b\": {\n\t\t\tid: \"openai/gpt-oss-20b\",\n\t\t\tname: \"OpenAI: gpt-oss-20b\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.03,\n\t\t\t\toutput: 0.14,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-oss-20b:free\": {\n\t\t\tid: \"openai/gpt-oss-20b:free\",\n\t\t\tname: \"OpenAI: gpt-oss-20b (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/gpt-oss-safeguard-20b\": {\n\t\t\tid: \"openai/gpt-oss-safeguard-20b\",\n\t\t\tname: \"OpenAI: gpt-oss-safeguard-20b\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.075,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0.037,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/o1\": {\n\t\t\tid: \"openai/o1\",\n\t\t\tname: \"OpenAI: o1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 60,\n\t\t\t\tcacheRead: 7.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/o3\": {\n\t\t\tid: \"openai/o3\",\n\t\t\tname: \"OpenAI: o3\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/o3-deep-research\": {\n\t\t\tid: \"openai/o3-deep-research\",\n\t\t\tname: \"OpenAI: o3 Deep Research\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 10,\n\t\t\t\toutput: 40,\n\t\t\t\tcacheRead: 2.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/o3-mini\": {\n\t\t\tid: \"openai/o3-mini\",\n\t\t\tname: \"OpenAI: o3 Mini\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.1,\n\t\t\t\toutput: 4.4,\n\t\t\t\tcacheRead: 0.55,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/o3-mini-high\": {\n\t\t\tid: \"openai/o3-mini-high\",\n\t\t\tname: \"OpenAI: o3 Mini High\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.1,\n\t\t\t\toutput: 4.4,\n\t\t\t\tcacheRead: 0.55,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/o3-pro\": {\n\t\t\tid: \"openai/o3-pro\",\n\t\t\tname: \"OpenAI: o3 Pro\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 20,\n\t\t\t\toutput: 80,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/o4-mini\": {\n\t\t\tid: \"openai/o4-mini\",\n\t\t\tname: \"OpenAI: o4 Mini\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.1,\n\t\t\t\toutput: 4.4,\n\t\t\t\tcacheRead: 0.275,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/o4-mini-deep-research\": {\n\t\t\tid: \"openai/o4-mini-deep-research\",\n\t\t\tname: \"OpenAI: o4 Mini Deep Research\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openai/o4-mini-high\": {\n\t\t\tid: \"openai/o4-mini-high\",\n\t\t\tname: \"OpenAI: o4 Mini High\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.1,\n\t\t\t\toutput: 4.4,\n\t\t\t\tcacheRead: 0.275,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openrouter/aurora-alpha\": {\n\t\t\tid: \"openrouter/aurora-alpha\",\n\t\t\tname: \"Aurora Alpha\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 50000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openrouter/auto\": {\n\t\t\tid: \"openrouter/auto\",\n\t\t\tname: \"Auto Router\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: -1000000,\n\t\t\t\toutput: -1000000,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 2000000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"openrouter/free\": {\n\t\t\tid: \"openrouter/free\",\n\t\t\tname: \"Free Models Router\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"prime-intellect/intellect-3\": {\n\t\t\tid: \"prime-intellect/intellect-3\",\n\t\t\tname: \"Prime Intellect: INTELLECT-3\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 1.1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen-2.5-72b-instruct\": {\n\t\t\tid: \"qwen/qwen-2.5-72b-instruct\",\n\t\t\tname: \"Qwen2.5 72B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.12,\n\t\t\t\toutput: 0.39,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen-2.5-7b-instruct\": {\n\t\t\tid: \"qwen/qwen-2.5-7b-instruct\",\n\t\t\tname: \"Qwen: Qwen2.5 7B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.04,\n\t\t\t\toutput: 0.09999999999999999,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen-max\": {\n\t\t\tid: \"qwen/qwen-max\",\n\t\t\tname: \"Qwen: Qwen-Max \",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.5999999999999999,\n\t\t\t\toutput: 6.3999999999999995,\n\t\t\t\tcacheRead: 0.32,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen-plus\": {\n\t\t\tid: \"qwen/qwen-plus\",\n\t\t\tname: \"Qwen: Qwen-Plus\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0.08,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen-plus-2025-07-28\": {\n\t\t\tid: \"qwen/qwen-plus-2025-07-28\",\n\t\t\tname: \"Qwen: Qwen Plus 0728\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen-plus-2025-07-28:thinking\": {\n\t\t\tid: \"qwen/qwen-plus-2025-07-28:thinking\",\n\t\t\tname: \"Qwen: Qwen Plus 0728 (thinking)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen-turbo\": {\n\t\t\tid: \"qwen/qwen-turbo\",\n\t\t\tname: \"Qwen: Qwen-Turbo\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.049999999999999996,\n\t\t\t\toutput: 0.19999999999999998,\n\t\t\t\tcacheRead: 0.01,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen-vl-max\": {\n\t\t\tid: \"qwen/qwen-vl-max\",\n\t\t\tname: \"Qwen: Qwen VL Max\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.7999999999999999,\n\t\t\t\toutput: 3.1999999999999997,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-14b\": {\n\t\t\tid: \"qwen/qwen3-14b\",\n\t\t\tname: \"Qwen: Qwen3 14B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.049999999999999996,\n\t\t\t\toutput: 0.22,\n\t\t\t\tcacheRead: 0.024999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 40960,\n\t\t\tmaxTokens: 40960,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-235b-a22b\": {\n\t\t\tid: \"qwen/qwen3-235b-a22b\",\n\t\t\tname: \"Qwen: Qwen3 235B A22B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0.15,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 40960,\n\t\t\tmaxTokens: 40960,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-235b-a22b-2507\": {\n\t\t\tid: \"qwen/qwen3-235b-a22b-2507\",\n\t\t\tname: \"Qwen: Qwen3 235B A22B Instruct 2507\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.071,\n\t\t\t\toutput: 0.09999999999999999,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-235b-a22b-thinking-2507\": {\n\t\t\tid: \"qwen/qwen3-235b-a22b-thinking-2507\",\n\t\t\tname: \"Qwen: Qwen3 235B A22B Thinking 2507\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-30b-a3b\": {\n\t\t\tid: \"qwen/qwen3-30b-a3b\",\n\t\t\tname: \"Qwen: Qwen3 30B A3B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.06,\n\t\t\t\toutput: 0.22,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 40960,\n\t\t\tmaxTokens: 40960,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-30b-a3b-instruct-2507\": {\n\t\t\tid: \"qwen/qwen3-30b-a3b-instruct-2507\",\n\t\t\tname: \"Qwen: Qwen3 30B A3B Instruct 2507\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.08,\n\t\t\t\toutput: 0.33,\n\t\t\t\tcacheRead: 0.04,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 262144,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-30b-a3b-thinking-2507\": {\n\t\t\tid: \"qwen/qwen3-30b-a3b-thinking-2507\",\n\t\t\tname: \"Qwen: Qwen3 30B A3B Thinking 2507\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.051,\n\t\t\t\toutput: 0.33999999999999997,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-32b\": {\n\t\t\tid: \"qwen/qwen3-32b\",\n\t\t\tname: \"Qwen: Qwen3 32B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.08,\n\t\t\t\toutput: 0.24,\n\t\t\t\tcacheRead: 0.04,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 40960,\n\t\t\tmaxTokens: 40960,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-4b\": {\n\t\t\tid: \"qwen/qwen3-4b\",\n\t\t\tname: \"Qwen: Qwen3 4B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.0715,\n\t\t\t\toutput: 0.273,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-4b:free\": {\n\t\t\tid: \"qwen/qwen3-4b:free\",\n\t\t\tname: \"Qwen: Qwen3 4B (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 40960,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-8b\": {\n\t\t\tid: \"qwen/qwen3-8b\",\n\t\t\tname: \"Qwen: Qwen3 8B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.049999999999999996,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0.049999999999999996,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-coder\": {\n\t\t\tid: \"qwen/qwen3-coder\",\n\t\t\tname: \"Qwen: Qwen3 Coder 480B A35B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.22,\n\t\t\t\toutput: 1,\n\t\t\t\tcacheRead: 0.022,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-coder-30b-a3b-instruct\": {\n\t\t\tid: \"qwen/qwen3-coder-30b-a3b-instruct\",\n\t\t\tname: \"Qwen: Qwen3 Coder 30B A3B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.07,\n\t\t\t\toutput: 0.27,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 160000,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-coder-flash\": {\n\t\t\tid: \"qwen/qwen3-coder-flash\",\n\t\t\tname: \"Qwen: Qwen3 Coder Flash\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0.06,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-coder-next\": {\n\t\t\tid: \"qwen/qwen3-coder-next\",\n\t\t\tname: \"Qwen: Qwen3 Coder Next\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.12,\n\t\t\t\toutput: 0.75,\n\t\t\t\tcacheRead: 0.06,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-coder-plus\": {\n\t\t\tid: \"qwen/qwen3-coder-plus\",\n\t\t\tname: \"Qwen: Qwen3 Coder Plus\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.19999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-coder:exacto\": {\n\t\t\tid: \"qwen/qwen3-coder:exacto\",\n\t\t\tname: \"Qwen: Qwen3 Coder 480B A35B (exacto)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.22,\n\t\t\t\toutput: 1.7999999999999998,\n\t\t\t\tcacheRead: 0.022,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-coder:free\": {\n\t\t\tid: \"qwen/qwen3-coder:free\",\n\t\t\tname: \"Qwen: Qwen3 Coder 480B A35B (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262000,\n\t\t\tmaxTokens: 262000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-max\": {\n\t\t\tid: \"qwen/qwen3-max\",\n\t\t\tname: \"Qwen: Qwen3 Max\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0.24,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-max-thinking\": {\n\t\t\tid: \"qwen/qwen3-max-thinking\",\n\t\t\tname: \"Qwen: Qwen3 Max Thinking\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-next-80b-a3b-instruct\": {\n\t\t\tid: \"qwen/qwen3-next-80b-a3b-instruct\",\n\t\t\tname: \"Qwen: Qwen3 Next 80B A3B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09,\n\t\t\t\toutput: 1.1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-next-80b-a3b-instruct:free\": {\n\t\t\tid: \"qwen/qwen3-next-80b-a3b-instruct:free\",\n\t\t\tname: \"Qwen: Qwen3 Next 80B A3B Instruct (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-next-80b-a3b-thinking\": {\n\t\t\tid: \"qwen/qwen3-next-80b-a3b-thinking\",\n\t\t\tname: \"Qwen: Qwen3 Next 80B A3B Thinking\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-vl-235b-a22b-instruct\": {\n\t\t\tid: \"qwen/qwen3-vl-235b-a22b-instruct\",\n\t\t\tname: \"Qwen: Qwen3 VL 235B A22B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 0.88,\n\t\t\t\tcacheRead: 0.11,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-vl-235b-a22b-thinking\": {\n\t\t\tid: \"qwen/qwen3-vl-235b-a22b-thinking\",\n\t\t\tname: \"Qwen: Qwen3 VL 235B A22B Thinking\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-vl-30b-a3b-instruct\": {\n\t\t\tid: \"qwen/qwen3-vl-30b-a3b-instruct\",\n\t\t\tname: \"Qwen: Qwen3 VL 30B A3B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.13,\n\t\t\t\toutput: 0.52,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-vl-30b-a3b-thinking\": {\n\t\t\tid: \"qwen/qwen3-vl-30b-a3b-thinking\",\n\t\t\tname: \"Qwen: Qwen3 VL 30B A3B Thinking\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-vl-32b-instruct\": {\n\t\t\tid: \"qwen/qwen3-vl-32b-instruct\",\n\t\t\tname: \"Qwen: Qwen3 VL 32B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.10400000000000001,\n\t\t\t\toutput: 0.41600000000000004,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-vl-8b-instruct\": {\n\t\t\tid: \"qwen/qwen3-vl-8b-instruct\",\n\t\t\tname: \"Qwen: Qwen3 VL 8B Instruct\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.08,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3-vl-8b-thinking\": {\n\t\t\tid: \"qwen/qwen3-vl-8b-thinking\",\n\t\t\tname: \"Qwen: Qwen3 VL 8B Thinking\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.117,\n\t\t\t\toutput: 1.365,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3.5-397b-a17b\": {\n\t\t\tid: \"qwen/qwen3.5-397b-a17b\",\n\t\t\tname: \"Qwen: Qwen3.5 397B A17B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 1,\n\t\t\t\tcacheRead: 0.15,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwen3.5-plus-02-15\": {\n\t\t\tid: \"qwen/qwen3.5-plus-02-15\",\n\t\t\tname: \"Qwen: Qwen3.5 Plus 2026-02-15\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 2.4,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"qwen/qwq-32b\": {\n\t\t\tid: \"qwen/qwq-32b\",\n\t\t\tname: \"Qwen: QwQ 32B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"relace/relace-search\": {\n\t\t\tid: \"relace/relace-search\",\n\t\t\tname: \"Relace: Relace Search\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"sao10k/l3-euryale-70b\": {\n\t\t\tid: \"sao10k/l3-euryale-70b\",\n\t\t\tname: \"Sao10k: Llama 3 Euryale 70B v2.1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.48,\n\t\t\t\toutput: 1.48,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8192,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"sao10k/l3.1-euryale-70b\": {\n\t\t\tid: \"sao10k/l3.1-euryale-70b\",\n\t\t\tname: \"Sao10K: Llama 3.1 Euryale 70B v2.2\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.65,\n\t\t\t\toutput: 0.75,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"stepfun/step-3.5-flash\": {\n\t\t\tid: \"stepfun/step-3.5-flash\",\n\t\t\tname: \"StepFun: Step 3.5 Flash\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0.02,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"stepfun/step-3.5-flash:free\": {\n\t\t\tid: \"stepfun/step-3.5-flash:free\",\n\t\t\tname: \"StepFun: Step 3.5 Flash (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"thedrummer/rocinante-12b\": {\n\t\t\tid: \"thedrummer/rocinante-12b\",\n\t\t\tname: \"TheDrummer: Rocinante 12B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.16999999999999998,\n\t\t\t\toutput: 0.43,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"thedrummer/unslopnemo-12b\": {\n\t\t\tid: \"thedrummer/unslopnemo-12b\",\n\t\t\tname: \"TheDrummer: UnslopNemo 12B\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"tngtech/deepseek-r1t2-chimera\": {\n\t\t\tid: \"tngtech/deepseek-r1t2-chimera\",\n\t\t\tname: \"TNG: DeepSeek R1T2 Chimera\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 0.85,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 163840,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"tngtech/tng-r1t-chimera\": {\n\t\t\tid: \"tngtech/tng-r1t-chimera\",\n\t\t\tname: \"TNG: R1T Chimera\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 0.85,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"upstage/solar-pro-3:free\": {\n\t\t\tid: \"upstage/solar-pro-3:free\",\n\t\t\tname: \"Upstage: Solar Pro 3 (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"x-ai/grok-3\": {\n\t\t\tid: \"x-ai/grok-3\",\n\t\t\tname: \"xAI: Grok 3\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.75,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"x-ai/grok-3-beta\": {\n\t\t\tid: \"x-ai/grok-3-beta\",\n\t\t\tname: \"xAI: Grok 3 Beta\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.75,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"x-ai/grok-3-mini\": {\n\t\t\tid: \"x-ai/grok-3-mini\",\n\t\t\tname: \"xAI: Grok 3 Mini\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.075,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"x-ai/grok-3-mini-beta\": {\n\t\t\tid: \"x-ai/grok-3-mini-beta\",\n\t\t\tname: \"xAI: Grok 3 Mini Beta\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.075,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"x-ai/grok-4\": {\n\t\t\tid: \"x-ai/grok-4\",\n\t\t\tname: \"xAI: Grok 4\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.75,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"x-ai/grok-4-fast\": {\n\t\t\tid: \"x-ai/grok-4-fast\",\n\t\t\tname: \"xAI: Grok 4 Fast\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.049999999999999996,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 2000000,\n\t\t\tmaxTokens: 30000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"x-ai/grok-4.1-fast\": {\n\t\t\tid: \"x-ai/grok-4.1-fast\",\n\t\t\tname: \"xAI: Grok 4.1 Fast\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.049999999999999996,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 2000000,\n\t\t\tmaxTokens: 30000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"x-ai/grok-code-fast-1\": {\n\t\t\tid: \"x-ai/grok-code-fast-1\",\n\t\t\tname: \"xAI: Grok Code Fast 1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0.02,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 10000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"xiaomi/mimo-v2-flash\": {\n\t\t\tid: \"xiaomi/mimo-v2-flash\",\n\t\t\tname: \"Xiaomi: MiMo-V2-Flash\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09,\n\t\t\t\toutput: 0.29,\n\t\t\t\tcacheRead: 0.045,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"z-ai/glm-4-32b\": {\n\t\t\tid: \"z-ai/glm-4-32b\",\n\t\t\tname: \"Z.ai: GLM 4 32B \",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.09999999999999999,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"z-ai/glm-4.5\": {\n\t\t\tid: \"z-ai/glm-4.5\",\n\t\t\tname: \"Z.ai: GLM 4.5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.35,\n\t\t\t\toutput: 1.55,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"z-ai/glm-4.5-air\": {\n\t\t\tid: \"z-ai/glm-4.5-air\",\n\t\t\tname: \"Z.ai: GLM 4.5 Air\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.13,\n\t\t\t\toutput: 0.85,\n\t\t\t\tcacheRead: 0.024999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 98304,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"z-ai/glm-4.5-air:free\": {\n\t\t\tid: \"z-ai/glm-4.5-air:free\",\n\t\t\tname: \"Z.ai: GLM 4.5 Air (free)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 96000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"z-ai/glm-4.5v\": {\n\t\t\tid: \"z-ai/glm-4.5v\",\n\t\t\tname: \"Z.ai: GLM 4.5V\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 1.7999999999999998,\n\t\t\t\tcacheRead: 0.11,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 65536,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"z-ai/glm-4.6\": {\n\t\t\tid: \"z-ai/glm-4.6\",\n\t\t\tname: \"Z.ai: GLM 4.6\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.33999999999999997,\n\t\t\t\toutput: 1.7,\n\t\t\t\tcacheRead: 0.16999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 202752,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"z-ai/glm-4.6:exacto\": {\n\t\t\tid: \"z-ai/glm-4.6:exacto\",\n\t\t\tname: \"Z.ai: GLM 4.6 (exacto)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.44,\n\t\t\t\toutput: 1.76,\n\t\t\t\tcacheRead: 0.11,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"z-ai/glm-4.6v\": {\n\t\t\tid: \"z-ai/glm-4.6v\",\n\t\t\tname: \"Z.ai: GLM 4.6V\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 0.8999999999999999,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"z-ai/glm-4.7\": {\n\t\t\tid: \"z-ai/glm-4.7\",\n\t\t\tname: \"Z.ai: GLM 4.7\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.38,\n\t\t\t\toutput: 1.7,\n\t\t\t\tcacheRead: 0.19,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 202752,\n\t\t\tmaxTokens: 65535,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"z-ai/glm-4.7-flash\": {\n\t\t\tid: \"z-ai/glm-4.7-flash\",\n\t\t\tname: \"Z.ai: GLM 4.7 Flash\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.06,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0.0100000002,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 202752,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"z-ai/glm-5\": {\n\t\t\tid: \"z-ai/glm-5\",\n\t\t\tname: \"Z.ai: GLM 5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"openrouter\",\n\t\t\tbaseUrl: \"https://openrouter.ai/api/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2.5500000000000003,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t},\n\t\"vercel-ai-gateway\": {\n\t\t\"alibaba/qwen-3-14b\": {\n\t\t\tid: \"alibaba/qwen-3-14b\",\n\t\t\tname: \"Qwen3-14B\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.06,\n\t\t\t\toutput: 0.24,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 40960,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"alibaba/qwen-3-235b\": {\n\t\t\tid: \"alibaba/qwen-3-235b\",\n\t\t\tname: \"Qwen3-235B-A22B\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.071,\n\t\t\t\toutput: 0.463,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 40960,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"alibaba/qwen-3-30b\": {\n\t\t\tid: \"alibaba/qwen-3-30b\",\n\t\t\tname: \"Qwen3-30B-A3B\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.08,\n\t\t\t\toutput: 0.29,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 40960,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"alibaba/qwen-3-32b\": {\n\t\t\tid: \"alibaba/qwen-3-32b\",\n\t\t\tname: \"Qwen 3 32B\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 40960,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"alibaba/qwen3-235b-a22b-thinking\": {\n\t\t\tid: \"alibaba/qwen3-235b-a22b-thinking\",\n\t\t\tname: \"Qwen3 235B A22B Thinking 2507\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2.9000000000000004,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262114,\n\t\t\tmaxTokens: 262114,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"alibaba/qwen3-coder\": {\n\t\t\tid: \"alibaba/qwen3-coder\",\n\t\t\tname: \"Qwen3 Coder 480B A35B Instruct\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 1.5999999999999999,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 66536,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"alibaba/qwen3-coder-30b-a3b\": {\n\t\t\tid: \"alibaba/qwen3-coder-30b-a3b\",\n\t\t\tname: \"Qwen 3 Coder 30B A3B Instruct\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.07,\n\t\t\t\toutput: 0.27,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 160000,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"alibaba/qwen3-coder-next\": {\n\t\t\tid: \"alibaba/qwen3-coder-next\",\n\t\t\tname: \"Qwen3 Coder Next\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"alibaba/qwen3-coder-plus\": {\n\t\t\tid: \"alibaba/qwen3-coder-plus\",\n\t\t\tname: \"Qwen3 Coder Plus\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.19999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"alibaba/qwen3-max-preview\": {\n\t\t\tid: \"alibaba/qwen3-max-preview\",\n\t\t\tname: \"Qwen3 Max Preview\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0.24,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"alibaba/qwen3-max-thinking\": {\n\t\t\tid: \"alibaba/qwen3-max-thinking\",\n\t\t\tname: \"Qwen 3 Max Thinking\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0.24,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"alibaba/qwen3-vl-thinking\": {\n\t\t\tid: \"alibaba/qwen3-vl-thinking\",\n\t\t\tname: \"Qwen3 VL 235B A22B Thinking\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.22,\n\t\t\t\toutput: 0.88,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"alibaba/qwen3.5-plus\": {\n\t\t\tid: \"alibaba/qwen3.5-plus\",\n\t\t\tname: \"Qwen 3.5 Plus\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 2.4,\n\t\t\t\tcacheRead: 0.04,\n\t\t\t\tcacheWrite: 0.5,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-3-haiku\": {\n\t\t\tid: \"anthropic/claude-3-haiku\",\n\t\t\tname: \"Claude 3 Haiku\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 1.25,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0.3,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-3.5-haiku\": {\n\t\t\tid: \"anthropic/claude-3.5-haiku\",\n\t\t\tname: \"Claude 3.5 Haiku\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.7999999999999999,\n\t\t\t\toutput: 4,\n\t\t\t\tcacheRead: 0.08,\n\t\t\t\tcacheWrite: 1,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-3.5-sonnet\": {\n\t\t\tid: \"anthropic/claude-3.5-sonnet\",\n\t\t\tname: \"Claude 3.5 Sonnet\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-3.5-sonnet-20240620\": {\n\t\t\tid: \"anthropic/claude-3.5-sonnet-20240620\",\n\t\t\tname: \"Claude 3.5 Sonnet (2024-06-20)\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-3.7-sonnet\": {\n\t\t\tid: \"anthropic/claude-3.7-sonnet\",\n\t\t\tname: \"Claude 3.7 Sonnet\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-haiku-4.5\": {\n\t\t\tid: \"anthropic/claude-haiku-4.5\",\n\t\t\tname: \"Claude Haiku 4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 5,\n\t\t\t\tcacheRead: 0.09999999999999999,\n\t\t\t\tcacheWrite: 1.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-opus-4\": {\n\t\t\tid: \"anthropic/claude-opus-4\",\n\t\t\tname: \"Claude Opus 4\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-opus-4.1\": {\n\t\t\tid: \"anthropic/claude-opus-4.1\",\n\t\t\tname: \"Claude Opus 4.1\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 75,\n\t\t\t\tcacheRead: 1.5,\n\t\t\t\tcacheWrite: 18.75,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-opus-4.5\": {\n\t\t\tid: \"anthropic/claude-opus-4.5\",\n\t\t\tname: \"Claude Opus 4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-opus-4.6\": {\n\t\t\tid: \"anthropic/claude-opus-4.6\",\n\t\t\tname: \"Claude Opus 4.6\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 6.25,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-sonnet-4\": {\n\t\t\tid: \"anthropic/claude-sonnet-4\",\n\t\t\tname: \"Claude Sonnet 4\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-sonnet-4.5\": {\n\t\t\tid: \"anthropic/claude-sonnet-4.5\",\n\t\t\tname: \"Claude Sonnet 4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"anthropic/claude-sonnet-4.6\": {\n\t\t\tid: \"anthropic/claude-sonnet-4.6\",\n\t\t\tname: \"Claude Sonnet 4.6\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.3,\n\t\t\t\tcacheWrite: 3.75,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"arcee-ai/trinity-large-preview\": {\n\t\t\tid: \"arcee-ai/trinity-large-preview\",\n\t\t\tname: \"Trinity Large Preview\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131000,\n\t\t\tmaxTokens: 131000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"bytedance/seed-1.6\": {\n\t\t\tid: \"bytedance/seed-1.6\",\n\t\t\tname: \"Seed 1.6\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.049999999999999996,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"cohere/command-a\": {\n\t\t\tid: \"cohere/command-a\",\n\t\t\tname: \"Command A\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 8000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"deepseek/deepseek-v3\": {\n\t\t\tid: \"deepseek/deepseek-v3\",\n\t\t\tname: \"DeepSeek V3 0324\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.77,\n\t\t\t\toutput: 0.77,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"deepseek/deepseek-v3.1\": {\n\t\t\tid: \"deepseek/deepseek-v3.1\",\n\t\t\tname: \"DeepSeek-V3.1\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.21,\n\t\t\t\toutput: 0.7899999999999999,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 163840,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"deepseek/deepseek-v3.1-terminus\": {\n\t\t\tid: \"deepseek/deepseek-v3.1-terminus\",\n\t\t\tname: \"DeepSeek V3.1 Terminus\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.27,\n\t\t\t\toutput: 1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"deepseek/deepseek-v3.2\": {\n\t\t\tid: \"deepseek/deepseek-v3.2\",\n\t\t\tname: \"DeepSeek V3.2\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.26,\n\t\t\t\toutput: 0.38,\n\t\t\t\tcacheRead: 0.13,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 8000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"deepseek/deepseek-v3.2-thinking\": {\n\t\t\tid: \"deepseek/deepseek-v3.2-thinking\",\n\t\t\tname: \"DeepSeek V3.2 Thinking\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.28,\n\t\t\t\toutput: 0.42,\n\t\t\t\tcacheRead: 0.028,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"google/gemini-2.5-flash\": {\n\t\t\tid: \"google/gemini-2.5-flash\",\n\t\t\tname: \"Gemini 2.5 Flash\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"google/gemini-2.5-flash-lite\": {\n\t\t\tid: \"google/gemini-2.5-flash-lite\",\n\t\t\tname: \"Gemini 2.5 Flash Lite\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0.01,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"google/gemini-2.5-flash-lite-preview-09-2025\": {\n\t\t\tid: \"google/gemini-2.5-flash-lite-preview-09-2025\",\n\t\t\tname: \"Gemini 2.5 Flash Lite Preview 09-2025\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0.01,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"google/gemini-2.5-flash-preview-09-2025\": {\n\t\t\tid: \"google/gemini-2.5-flash-preview-09-2025\",\n\t\t\tname: \"Gemini 2.5 Flash Preview 09-2025\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2.5,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"google/gemini-2.5-pro\": {\n\t\t\tid: \"google/gemini-2.5-pro\",\n\t\t\tname: \"Gemini 2.5 Pro\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1048576,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"google/gemini-3-flash\": {\n\t\t\tid: \"google/gemini-3-flash\",\n\t\t\tname: \"Gemini 3 Flash\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 3,\n\t\t\t\tcacheRead: 0.049999999999999996,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"google/gemini-3-pro-preview\": {\n\t\t\tid: \"google/gemini-3-pro-preview\",\n\t\t\tname: \"Gemini 3 Pro Preview\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 12,\n\t\t\t\tcacheRead: 0.19999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1000000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"inception/mercury-coder-small\": {\n\t\t\tid: \"inception/mercury-coder-small\",\n\t\t\tname: \"Mercury Coder Small Beta\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"meituan/longcat-flash-chat\": {\n\t\t\tid: \"meituan/longcat-flash-chat\",\n\t\t\tname: \"LongCat Flash Chat\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"meituan/longcat-flash-thinking\": {\n\t\t\tid: \"meituan/longcat-flash-thinking\",\n\t\t\tname: \"LongCat Flash Thinking\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"meta/llama-3.1-70b\": {\n\t\t\tid: \"meta/llama-3.1-70b\",\n\t\t\tname: \"Llama 3.1 70B Instruct\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"meta/llama-3.1-8b\": {\n\t\t\tid: \"meta/llama-3.1-8b\",\n\t\t\tname: \"Llama 3.1 8B Instruct\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.03,\n\t\t\t\toutput: 0.049999999999999996,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"meta/llama-3.2-11b\": {\n\t\t\tid: \"meta/llama-3.2-11b\",\n\t\t\tname: \"Llama 3.2 11B Vision Instruct\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.16,\n\t\t\t\toutput: 0.16,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"meta/llama-3.2-90b\": {\n\t\t\tid: \"meta/llama-3.2-90b\",\n\t\t\tname: \"Llama 3.2 90B Vision Instruct\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.72,\n\t\t\t\toutput: 0.72,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"meta/llama-3.3-70b\": {\n\t\t\tid: \"meta/llama-3.3-70b\",\n\t\t\tname: \"Llama 3.3 70B Instruct\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.72,\n\t\t\t\toutput: 0.72,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"meta/llama-4-maverick\": {\n\t\t\tid: \"meta/llama-4-maverick\",\n\t\t\tname: \"Llama 4 Maverick 17B Instruct\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"meta/llama-4-scout\": {\n\t\t\tid: \"meta/llama-4-scout\",\n\t\t\tname: \"Llama 4 Scout 17B Instruct\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.08,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"minimax/minimax-m2\": {\n\t\t\tid: \"minimax/minimax-m2\",\n\t\t\tname: \"MiniMax M2\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0.375,\n\t\t\t},\n\t\t\tcontextWindow: 205000,\n\t\t\tmaxTokens: 205000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"minimax/minimax-m2.1\": {\n\t\t\tid: \"minimax/minimax-m2.1\",\n\t\t\tname: \"MiniMax M2.1\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0.15,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"minimax/minimax-m2.1-lightning\": {\n\t\t\tid: \"minimax/minimax-m2.1-lightning\",\n\t\t\tname: \"MiniMax M2.1 Lightning\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 2.4,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0.375,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"minimax/minimax-m2.5\": {\n\t\t\tid: \"minimax/minimax-m2.5\",\n\t\t\tname: \"MiniMax M2.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 1.2,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0.375,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"mistral/codestral\": {\n\t\t\tid: \"mistral/codestral\",\n\t\t\tname: \"Mistral Codestral\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 0.8999999999999999,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"mistral/devstral-2\": {\n\t\t\tid: \"mistral/devstral-2\",\n\t\t\tname: \"Devstral 2\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"mistral/devstral-small\": {\n\t\t\tid: \"mistral/devstral-small\",\n\t\t\tname: \"Devstral Small 1.1\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"mistral/devstral-small-2\": {\n\t\t\tid: \"mistral/devstral-small-2\",\n\t\t\tname: \"Devstral Small 2\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"mistral/ministral-3b\": {\n\t\t\tid: \"mistral/ministral-3b\",\n\t\t\tname: \"Ministral 3B\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.04,\n\t\t\t\toutput: 0.04,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"mistral/ministral-8b\": {\n\t\t\tid: \"mistral/ministral-8b\",\n\t\t\tname: \"Ministral 8B\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.09999999999999999,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"mistral/mistral-medium\": {\n\t\t\tid: \"mistral/mistral-medium\",\n\t\t\tname: \"Mistral Medium 3.1\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"mistral/mistral-small\": {\n\t\t\tid: \"mistral/mistral-small\",\n\t\t\tname: \"Mistral Small\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32000,\n\t\t\tmaxTokens: 4000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"mistral/pixtral-12b\": {\n\t\t\tid: \"mistral/pixtral-12b\",\n\t\t\tname: \"Pixtral 12B 2409\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"mistral/pixtral-large\": {\n\t\t\tid: \"mistral/pixtral-large\",\n\t\t\tname: \"Pixtral Large\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"moonshotai/kimi-k2\": {\n\t\t\tid: \"moonshotai/kimi-k2\",\n\t\t\tname: \"Kimi K2\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"moonshotai/kimi-k2-thinking\": {\n\t\t\tid: \"moonshotai/kimi-k2-thinking\",\n\t\t\tname: \"Kimi K2 Thinking\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.47,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.14100000000000001,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 216144,\n\t\t\tmaxTokens: 216144,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"moonshotai/kimi-k2-thinking-turbo\": {\n\t\t\tid: \"moonshotai/kimi-k2-thinking-turbo\",\n\t\t\tname: \"Kimi K2 Thinking Turbo\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.15,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0.15,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262114,\n\t\t\tmaxTokens: 262114,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"moonshotai/kimi-k2-turbo\": {\n\t\t\tid: \"moonshotai/kimi-k2-turbo\",\n\t\t\tname: \"Kimi K2 Turbo\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.4,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"moonshotai/kimi-k2.5\": {\n\t\t\tid: \"moonshotai/kimi-k2.5\",\n\t\t\tname: \"Kimi K2.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.5,\n\t\t\t\toutput: 2.8,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"nvidia/nemotron-nano-12b-v2-vl\": {\n\t\t\tid: \"nvidia/nemotron-nano-12b-v2-vl\",\n\t\t\tname: \"Nvidia Nemotron Nano 12B V2 VL\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"nvidia/nemotron-nano-9b-v2\": {\n\t\t\tid: \"nvidia/nemotron-nano-9b-v2\",\n\t\t\tname: \"Nvidia Nemotron Nano 9B V2\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.04,\n\t\t\t\toutput: 0.16,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/codex-mini\": {\n\t\t\tid: \"openai/codex-mini\",\n\t\t\tname: \"Codex Mini\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.5,\n\t\t\t\toutput: 6,\n\t\t\t\tcacheRead: 0.375,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-4-turbo\": {\n\t\t\tid: \"openai/gpt-4-turbo\",\n\t\t\tname: \"GPT-4 Turbo\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 10,\n\t\t\t\toutput: 30,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-4.1\": {\n\t\t\tid: \"openai/gpt-4.1\",\n\t\t\tname: \"GPT-4.1\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1047576,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-4.1-mini\": {\n\t\t\tid: \"openai/gpt-4.1-mini\",\n\t\t\tname: \"GPT-4.1 mini\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.39999999999999997,\n\t\t\t\toutput: 1.5999999999999999,\n\t\t\t\tcacheRead: 0.09999999999999999,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1047576,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-4.1-nano\": {\n\t\t\tid: \"openai/gpt-4.1-nano\",\n\t\t\tname: \"GPT-4.1 nano\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 1047576,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-4o\": {\n\t\t\tid: \"openai/gpt-4o\",\n\t\t\tname: \"GPT-4o\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2.5,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-4o-mini\": {\n\t\t\tid: \"openai/gpt-4o-mini\",\n\t\t\tname: \"GPT-4o mini\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.15,\n\t\t\t\toutput: 0.6,\n\t\t\t\tcacheRead: 0.075,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5\": {\n\t\t\tid: \"openai/gpt-5\",\n\t\t\tname: \"GPT-5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.13,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5-chat\": {\n\t\t\tid: \"openai/gpt-5-chat\",\n\t\t\tname: \"GPT-5 Chat\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5-codex\": {\n\t\t\tid: \"openai/gpt-5-codex\",\n\t\t\tname: \"GPT-5-Codex\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.13,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5-mini\": {\n\t\t\tid: \"openai/gpt-5-mini\",\n\t\t\tname: \"GPT-5 mini\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5-nano\": {\n\t\t\tid: \"openai/gpt-5-nano\",\n\t\t\tname: \"GPT-5 nano\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.049999999999999996,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0.01,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5-pro\": {\n\t\t\tid: \"openai/gpt-5-pro\",\n\t\t\tname: \"GPT-5 pro\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 120,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 272000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5.1-codex\": {\n\t\t\tid: \"openai/gpt-5.1-codex\",\n\t\t\tname: \"GPT-5.1-Codex\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.13,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5.1-codex-max\": {\n\t\t\tid: \"openai/gpt-5.1-codex-max\",\n\t\t\tname: \"GPT 5.1 Codex Max\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.125,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5.1-codex-mini\": {\n\t\t\tid: \"openai/gpt-5.1-codex-mini\",\n\t\t\tname: \"GPT-5.1 Codex mini\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.25,\n\t\t\t\toutput: 2,\n\t\t\t\tcacheRead: 0.024999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5.1-instant\": {\n\t\t\tid: \"openai/gpt-5.1-instant\",\n\t\t\tname: \"GPT-5.1 Instant\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.13,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5.1-thinking\": {\n\t\t\tid: \"openai/gpt-5.1-thinking\",\n\t\t\tname: \"GPT 5.1 Thinking\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.25,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0.13,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5.2\": {\n\t\t\tid: \"openai/gpt-5.2\",\n\t\t\tname: \"GPT 5.2\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.18,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5.2-chat\": {\n\t\t\tid: \"openai/gpt-5.2-chat\",\n\t\t\tname: \"GPT-5.2 Chat\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5.2-codex\": {\n\t\t\tid: \"openai/gpt-5.2-codex\",\n\t\t\tname: \"GPT-5.2-Codex\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.75,\n\t\t\t\toutput: 14,\n\t\t\t\tcacheRead: 0.175,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-5.2-pro\": {\n\t\t\tid: \"openai/gpt-5.2-pro\",\n\t\t\tname: \"GPT 5.2 \",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 21,\n\t\t\t\toutput: 168,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 400000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-oss-120b\": {\n\t\t\tid: \"openai/gpt-oss-120b\",\n\t\t\tname: \"gpt-oss-120b\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09999999999999999,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-oss-20b\": {\n\t\t\tid: \"openai/gpt-oss-20b\",\n\t\t\tname: \"gpt-oss-20b\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.07,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/gpt-oss-safeguard-20b\": {\n\t\t\tid: \"openai/gpt-oss-safeguard-20b\",\n\t\t\tname: \"gpt-oss-safeguard-20b\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.075,\n\t\t\t\toutput: 0.3,\n\t\t\t\tcacheRead: 0.037,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 65536,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/o1\": {\n\t\t\tid: \"openai/o1\",\n\t\t\tname: \"o1\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 15,\n\t\t\t\toutput: 60,\n\t\t\t\tcacheRead: 7.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/o3\": {\n\t\t\tid: \"openai/o3\",\n\t\t\tname: \"o3\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 8,\n\t\t\t\tcacheRead: 0.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/o3-deep-research\": {\n\t\t\tid: \"openai/o3-deep-research\",\n\t\t\tname: \"o3-deep-research\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 10,\n\t\t\t\toutput: 40,\n\t\t\t\tcacheRead: 2.5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/o3-mini\": {\n\t\t\tid: \"openai/o3-mini\",\n\t\t\tname: \"o3-mini\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.1,\n\t\t\t\toutput: 4.4,\n\t\t\t\tcacheRead: 0.55,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/o3-pro\": {\n\t\t\tid: \"openai/o3-pro\",\n\t\t\tname: \"o3 Pro\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 20,\n\t\t\t\toutput: 80,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"openai/o4-mini\": {\n\t\t\tid: \"openai/o4-mini\",\n\t\t\tname: \"o4-mini\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1.1,\n\t\t\t\toutput: 4.4,\n\t\t\t\tcacheRead: 0.275,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 100000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"perplexity/sonar\": {\n\t\t\tid: \"perplexity/sonar\",\n\t\t\tname: \"Sonar\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 127000,\n\t\t\tmaxTokens: 8000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"perplexity/sonar-pro\": {\n\t\t\tid: \"perplexity/sonar-pro\",\n\t\t\tname: \"Sonar Pro\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 8000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"prime-intellect/intellect-3\": {\n\t\t\tid: \"prime-intellect/intellect-3\",\n\t\t\tname: \"INTELLECT 3\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 1.1,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"vercel/v0-1.0-md\": {\n\t\t\tid: \"vercel/v0-1.0-md\",\n\t\t\tname: \"v0-1.0-md\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"vercel/v0-1.5-md\": {\n\t\t\tid: \"vercel/v0-1.5-md\",\n\t\t\tname: \"v0-1.5-md\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"xai/grok-2-vision\": {\n\t\t\tid: \"xai/grok-2-vision\",\n\t\t\tname: \"Grok 2 Vision\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 32768,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"xai/grok-3\": {\n\t\t\tid: \"xai/grok-3\",\n\t\t\tname: \"Grok 3 Beta\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"xai/grok-3-fast\": {\n\t\t\tid: \"xai/grok-3-fast\",\n\t\t\tname: \"Grok 3 Fast Beta\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"xai/grok-3-mini\": {\n\t\t\tid: \"xai/grok-3-mini\",\n\t\t\tname: \"Grok 3 Mini Beta\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"xai/grok-3-mini-fast\": {\n\t\t\tid: \"xai/grok-3-mini-fast\",\n\t\t\tname: \"Grok 3 Mini Fast Beta\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 4,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"xai/grok-4\": {\n\t\t\tid: \"xai/grok-4\",\n\t\t\tname: \"Grok 4\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"xai/grok-4-fast-non-reasoning\": {\n\t\t\tid: \"xai/grok-4-fast-non-reasoning\",\n\t\t\tname: \"Grok 4 Fast Non-Reasoning\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.049999999999999996,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 2000000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"xai/grok-4-fast-reasoning\": {\n\t\t\tid: \"xai/grok-4-fast-reasoning\",\n\t\t\tname: \"Grok 4 Fast Reasoning\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.049999999999999996,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 2000000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"xai/grok-4.1-fast-non-reasoning\": {\n\t\t\tid: \"xai/grok-4.1-fast-non-reasoning\",\n\t\t\tname: \"Grok 4.1 Fast Non-Reasoning\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.049999999999999996,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 2000000,\n\t\t\tmaxTokens: 30000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"xai/grok-4.1-fast-reasoning\": {\n\t\t\tid: \"xai/grok-4.1-fast-reasoning\",\n\t\t\tname: \"Grok 4.1 Fast Reasoning\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.049999999999999996,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 2000000,\n\t\t\tmaxTokens: 30000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"xai/grok-code-fast-1\": {\n\t\t\tid: \"xai/grok-code-fast-1\",\n\t\t\tname: \"Grok Code Fast 1\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0.02,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 256000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"xiaomi/mimo-v2-flash\": {\n\t\t\tid: \"xiaomi/mimo-v2-flash\",\n\t\t\tname: \"MiMo V2 Flash\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.09,\n\t\t\t\toutput: 0.29,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 262144,\n\t\t\tmaxTokens: 32000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"zai/glm-4.5\": {\n\t\t\tid: \"zai/glm-4.5\",\n\t\t\tname: \"GLM-4.5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.2,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"zai/glm-4.5-air\": {\n\t\t\tid: \"zai/glm-4.5-air\",\n\t\t\tname: \"GLM 4.5 Air\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.19999999999999998,\n\t\t\t\toutput: 1.1,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 96000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"zai/glm-4.5v\": {\n\t\t\tid: \"zai/glm-4.5v\",\n\t\t\tname: \"GLM 4.5V\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 1.7999999999999998,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 65536,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"zai/glm-4.6\": {\n\t\t\tid: \"zai/glm-4.6\",\n\t\t\tname: \"GLM 4.6\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.44999999999999996,\n\t\t\t\toutput: 1.7999999999999998,\n\t\t\t\tcacheRead: 0.11,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 96000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"zai/glm-4.6v\": {\n\t\t\tid: \"zai/glm-4.6v\",\n\t\t\tname: \"GLM-4.6V\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 0.8999999999999999,\n\t\t\t\tcacheRead: 0.049999999999999996,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 24000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"zai/glm-4.6v-flash\": {\n\t\t\tid: \"zai/glm-4.6v-flash\",\n\t\t\tname: \"GLM-4.6V-Flash\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 24000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"zai/glm-4.7\": {\n\t\t\tid: \"zai/glm-4.7\",\n\t\t\tname: \"GLM 4.7\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.43,\n\t\t\t\toutput: 1.75,\n\t\t\t\tcacheRead: 0.08,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 202752,\n\t\t\tmaxTokens: 120000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"zai/glm-4.7-flashx\": {\n\t\t\tid: \"zai/glm-4.7-flashx\",\n\t\t\tname: \"GLM 4.7 FlashX\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.06,\n\t\t\t\toutput: 0.39999999999999997,\n\t\t\t\tcacheRead: 0.01,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 128000,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t\t\"zai/glm-5\": {\n\t\t\tid: \"zai/glm-5\",\n\t\t\tname: \"GLM-5\",\n\t\t\tapi: \"anthropic-messages\",\n\t\t\tprovider: \"vercel-ai-gateway\",\n\t\t\tbaseUrl: \"https://ai-gateway.vercel.sh\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 3.1999999999999997,\n\t\t\t\tcacheRead: 0.19999999999999998,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 202800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"anthropic-messages\">,\n\t},\n\t\"xai\": {\n\t\t\"grok-2\": {\n\t\t\tid: \"grok-2\",\n\t\t\tname: \"Grok 2\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-2-1212\": {\n\t\t\tid: \"grok-2-1212\",\n\t\t\tname: \"Grok 2 (1212)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-2-latest\": {\n\t\t\tid: \"grok-2-latest\",\n\t\t\tname: \"Grok 2 Latest\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-2-vision\": {\n\t\t\tid: \"grok-2-vision\",\n\t\t\tname: \"Grok 2 Vision\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8192,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-2-vision-1212\": {\n\t\t\tid: \"grok-2-vision-1212\",\n\t\t\tname: \"Grok 2 Vision (1212)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8192,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-2-vision-latest\": {\n\t\t\tid: \"grok-2-vision-latest\",\n\t\t\tname: \"Grok 2 Vision Latest\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 2,\n\t\t\t\toutput: 10,\n\t\t\t\tcacheRead: 2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8192,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-3\": {\n\t\t\tid: \"grok-3\",\n\t\t\tname: \"Grok 3\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.75,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-3-fast\": {\n\t\t\tid: \"grok-3-fast\",\n\t\t\tname: \"Grok 3 Fast\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-3-fast-latest\": {\n\t\t\tid: \"grok-3-fast-latest\",\n\t\t\tname: \"Grok 3 Fast Latest\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 25,\n\t\t\t\tcacheRead: 1.25,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-3-latest\": {\n\t\t\tid: \"grok-3-latest\",\n\t\t\tname: \"Grok 3 Latest\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.75,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-3-mini\": {\n\t\t\tid: \"grok-3-mini\",\n\t\t\tname: \"Grok 3 Mini\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.075,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-3-mini-fast\": {\n\t\t\tid: \"grok-3-mini-fast\",\n\t\t\tname: \"Grok 3 Mini Fast\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 4,\n\t\t\t\tcacheRead: 0.15,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-3-mini-fast-latest\": {\n\t\t\tid: \"grok-3-mini-fast-latest\",\n\t\t\tname: \"Grok 3 Mini Fast Latest\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 4,\n\t\t\t\tcacheRead: 0.15,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-3-mini-latest\": {\n\t\t\tid: \"grok-3-mini-latest\",\n\t\t\tname: \"Grok 3 Mini Latest\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.075,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 8192,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-4\": {\n\t\t\tid: \"grok-4\",\n\t\t\tname: \"Grok 4\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 3,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 0.75,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 64000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-4-1-fast\": {\n\t\t\tid: \"grok-4-1-fast\",\n\t\t\tname: \"Grok 4.1 Fast\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.05,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 2000000,\n\t\t\tmaxTokens: 30000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-4-1-fast-non-reasoning\": {\n\t\t\tid: \"grok-4-1-fast-non-reasoning\",\n\t\t\tname: \"Grok 4.1 Fast (Non-Reasoning)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.05,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 2000000,\n\t\t\tmaxTokens: 30000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-4-fast\": {\n\t\t\tid: \"grok-4-fast\",\n\t\t\tname: \"Grok 4 Fast\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.05,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 2000000,\n\t\t\tmaxTokens: 30000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-4-fast-non-reasoning\": {\n\t\t\tid: \"grok-4-fast-non-reasoning\",\n\t\t\tname: \"Grok 4 Fast (Non-Reasoning)\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 0.5,\n\t\t\t\tcacheRead: 0.05,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 2000000,\n\t\t\tmaxTokens: 30000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-beta\": {\n\t\t\tid: \"grok-beta\",\n\t\t\tname: \"Grok Beta\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-code-fast-1\": {\n\t\t\tid: \"grok-code-fast-1\",\n\t\t\tname: \"Grok Code Fast 1\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 1.5,\n\t\t\t\tcacheRead: 0.02,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 256000,\n\t\t\tmaxTokens: 10000,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"grok-vision-beta\": {\n\t\t\tid: \"grok-vision-beta\",\n\t\t\tname: \"Grok Vision Beta\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"xai\",\n\t\t\tbaseUrl: \"https://api.x.ai/v1\",\n\t\t\treasoning: false,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 5,\n\t\t\t\toutput: 15,\n\t\t\t\tcacheRead: 5,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 8192,\n\t\t\tmaxTokens: 4096,\n\t\t} satisfies Model<\"openai-completions\">,\n\t},\n\t\"zai\": {\n\t\t\"glm-4.5\": {\n\t\t\tid: \"glm-4.5\",\n\t\t\tname: \"GLM-4.5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"zai\",\n\t\t\tbaseUrl: \"https://api.z.ai/api/coding/paas/v4\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false,\"thinkingFormat\":\"zai\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.2,\n\t\t\t\tcacheRead: 0.11,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 98304,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"glm-4.5-air\": {\n\t\t\tid: \"glm-4.5-air\",\n\t\t\tname: \"GLM-4.5-Air\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"zai\",\n\t\t\tbaseUrl: \"https://api.z.ai/api/coding/paas/v4\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false,\"thinkingFormat\":\"zai\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.2,\n\t\t\t\toutput: 1.1,\n\t\t\t\tcacheRead: 0.03,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 98304,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"glm-4.5-flash\": {\n\t\t\tid: \"glm-4.5-flash\",\n\t\t\tname: \"GLM-4.5-Flash\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"zai\",\n\t\t\tbaseUrl: \"https://api.z.ai/api/coding/paas/v4\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false,\"thinkingFormat\":\"zai\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 131072,\n\t\t\tmaxTokens: 98304,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"glm-4.5v\": {\n\t\t\tid: \"glm-4.5v\",\n\t\t\tname: \"GLM-4.5V\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"zai\",\n\t\t\tbaseUrl: \"https://api.z.ai/api/coding/paas/v4\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false,\"thinkingFormat\":\"zai\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 1.8,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 64000,\n\t\t\tmaxTokens: 16384,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"glm-4.6\": {\n\t\t\tid: \"glm-4.6\",\n\t\t\tname: \"GLM-4.6\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"zai\",\n\t\t\tbaseUrl: \"https://api.z.ai/api/coding/paas/v4\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false,\"thinkingFormat\":\"zai\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.2,\n\t\t\t\tcacheRead: 0.11,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"glm-4.6v\": {\n\t\t\tid: \"glm-4.6v\",\n\t\t\tname: \"GLM-4.6V\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"zai\",\n\t\t\tbaseUrl: \"https://api.z.ai/api/coding/paas/v4\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false,\"thinkingFormat\":\"zai\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\", \"image\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.3,\n\t\t\t\toutput: 0.9,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 128000,\n\t\t\tmaxTokens: 32768,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"glm-4.7\": {\n\t\t\tid: \"glm-4.7\",\n\t\t\tname: \"GLM-4.7\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"zai\",\n\t\t\tbaseUrl: \"https://api.z.ai/api/coding/paas/v4\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false,\"thinkingFormat\":\"zai\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0.6,\n\t\t\t\toutput: 2.2,\n\t\t\t\tcacheRead: 0.11,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"glm-4.7-flash\": {\n\t\t\tid: \"glm-4.7-flash\",\n\t\t\tname: \"GLM-4.7-Flash\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"zai\",\n\t\t\tbaseUrl: \"https://api.z.ai/api/coding/paas/v4\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false,\"thinkingFormat\":\"zai\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 0,\n\t\t\t\toutput: 0,\n\t\t\t\tcacheRead: 0,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 200000,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t\t\"glm-5\": {\n\t\t\tid: \"glm-5\",\n\t\t\tname: \"GLM-5\",\n\t\t\tapi: \"openai-completions\",\n\t\t\tprovider: \"zai\",\n\t\t\tbaseUrl: \"https://api.z.ai/api/coding/paas/v4\",\n\t\t\tcompat: {\"supportsDeveloperRole\":false,\"thinkingFormat\":\"zai\"},\n\t\t\treasoning: true,\n\t\t\tinput: [\"text\"],\n\t\t\tcost: {\n\t\t\t\tinput: 1,\n\t\t\t\toutput: 3.2,\n\t\t\t\tcacheRead: 0.2,\n\t\t\t\tcacheWrite: 0,\n\t\t\t},\n\t\t\tcontextWindow: 204800,\n\t\t\tmaxTokens: 131072,\n\t\t} satisfies Model<\"openai-completions\">,\n\t},\n} as const;\n"]}